{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Installing Requirements"
      ],
      "metadata": {
        "id": "ImQENjSq1IqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL3nlPN5U_k3"
      },
      "outputs": [],
      "source": [
        "# Installing finRL\n",
        "!pip install swig\n",
        "!pip install wrds\n",
        "!pip install pyportfolioopt\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "\n",
        "# Installing Talib\n",
        "url = 'https://anaconda.org/conda-forge/libta-lib/0.4.0/download/linux-64/libta-lib-0.4.0-h166bdaf_1.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/lib/x86_64-linux-gnu/ lib --strip-components=1\n",
        "url = 'https://anaconda.org/conda-forge/ta-lib/0.4.19/download/linux-64/ta-lib-0.4.19-py310hde88566_4.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/local/lib/python3.10/dist-packages/ lib/python3.10/site-packages/talib --strip-components=3\n",
        "\n",
        "#Installing Alphavantage\n",
        "!pip install alpha_vantage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing neccessary libraries and dependencies"
      ],
      "metadata": {
        "id": "vslg-XE81RKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "\n",
        "#FinRl requirements\n",
        "from finrl import config_tickers\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from stable_baselines3.common import utils\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "check_and_make_directories([TRAINED_MODEL_DIR])\n",
        "import itertools\n",
        "import talib\n",
        "\n",
        "#Other dependecies\n",
        "from alpha_vantage.fundamentaldata import FundamentalData\n",
        "from stable_baselines3 import DDPG, PPO\n",
        "from plotnine import *\n",
        "import seaborn as sns\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3 import DDPG, PPO\n",
        "import plotly.graph_objs as go\n",
        "from finrl import config_tickers\n",
        "\n",
        "#Portfolio environment requirements\n",
        "import os\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv"
      ],
      "metadata": {
        "id": "vMw51mPNVFZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessor Class:\n",
        "* Download the required data for the train and test period for all the DOW_30 tickers.\n",
        "* Calculate corresponding technical indicators as well as fundamental data using Alpha vatage.\n",
        "* Preprocess and normalize the data"
      ],
      "metadata": {
        "id": "s-AjuOS81WoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataProcessor:\n",
        "    def __init__(self, Train_start, Test_start, Train_end, Test_end, config_tickers):\n",
        "        \"\"\"\n",
        "        Initialize DataProcessor with start and end dates for training and testing periods,\n",
        "        along with a configuration of tickers.\n",
        "\n",
        "        Args:\n",
        "        - Train_start (str): Start date for the training period.\n",
        "        - Test_start (str): Start date for the testing period.\n",
        "        - Train_end (str): End date for the training period.\n",
        "        - Test_end (str): End date for the testing period.\n",
        "        - config_tickers (object): Object containing ticker configuration.\n",
        "        \"\"\"\n",
        "        self.Train_start = Train_start\n",
        "        self.Test_start = Test_start\n",
        "        self.Train_end = Train_end\n",
        "        self.Test_end = Test_end\n",
        "        self.config_tickers = config_tickers\n",
        "        self.yahoo_downloader = YahooDownloader(start_date=self.Train_start,\n",
        "                                                end_date=self.Test_end,\n",
        "                                                ticker_list=self.config_tickers.DOW_30_TICKER)\n",
        "        self.df_temp = None\n",
        "        self.fundamental_data = None\n",
        "        self.df_new = None\n",
        "\n",
        "    def fetch_data(self):\n",
        "        \"\"\"\n",
        "        Fetch data from Yahoo Finance API and calculate volatility.\n",
        "        \"\"\"\n",
        "        self.df_temp = self.yahoo_downloader.fetch_data()\n",
        "        self.df_temp['return'] = self.df_temp.groupby('tic')['close'].pct_change()\n",
        "        df_sorted = self.df_temp.sort_values(by='date', ascending=False)\n",
        "        recent_returns = df_sorted.groupby('tic').head(14)\n",
        "        volatility_per_symbol = recent_returns.groupby('tic')['return'].std()\n",
        "        self.df_temp = self.df_temp.merge(volatility_per_symbol, on='tic', suffixes=('', '_volatility'))\n",
        "        self.df_temp.rename(columns={'return_volatility': 'volatility'}, inplace=True)\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"\n",
        "        Preprocess data including feature engineering and technical indicators calculation.\n",
        "        \"\"\"\n",
        "        fe = FeatureEngineer(\n",
        "            use_technical_indicator=True,\n",
        "            tech_indicator_list=INDICATORS,\n",
        "            use_vix=True,\n",
        "            use_turbulence=True,\n",
        "            user_defined_feature=False\n",
        "        )\n",
        "        self.df_new = fe.preprocess_data(self.df_temp)\n",
        "\n",
        "        sar_values = self.df_new.groupby('tic').apply(lambda x: talib.SAR(x['high'], x['low']))\n",
        "        adx_values = self.df_new.groupby('tic').apply(lambda x: talib.ADX(x['high'], x['low'], x['close']))\n",
        "\n",
        "        self.df_new['sar'] = sar_values.values\n",
        "        self.df_new['adx'] = adx_values.values\n",
        "        self.df_new['true_range'] = np.nan\n",
        "        for ticker in self.df_new['tic'].unique():\n",
        "            mask = self.df_new['tic'] == ticker\n",
        "            high = self.df_new.loc[mask, 'high']\n",
        "            low = self.df_new.loc[mask, 'low']\n",
        "            close_prev = self.df_new.loc[mask, 'close'].shift(1)\n",
        "\n",
        "            # Calculate true range\n",
        "            true_range = np.maximum.reduce([\n",
        "                high - low,\n",
        "                abs(high - close_prev),\n",
        "                abs(low - close_prev)\n",
        "            ])\n",
        "            # Assign true range values to the corresponding rows\n",
        "            self.df_new.loc[mask, 'true_range'] = true_range\n",
        "\n",
        "\n",
        "    def fetch_fundamental_data(self):\n",
        "        \"\"\"\n",
        "        Fetch fundamental data using Alpha Vantage API.\n",
        "        \"\"\"\n",
        "        api_key = 'AI9IKPBRI8DXDXPI'\n",
        "        fd = FundamentalData(key=api_key)\n",
        "        fundamental_data = {}\n",
        "        for ticker in self.config_tickers.DOW_30_TICKER:\n",
        "            overview_data, meta_data = fd.get_company_overview(symbol=ticker)\n",
        "            fundamental_data[ticker] = {\n",
        "                'book_value_per_share': float(overview_data['BookValue']),\n",
        "                'sales_per_share': float(overview_data['RevenuePerShareTTM'])\n",
        "            }\n",
        "        self.fundamental_data = fundamental_data\n",
        "\n",
        "    def calculate_ratios(self, row):\n",
        "        \"\"\"\n",
        "        Calculate price-to-book and price-to-sales ratios for each row.\n",
        "        \"\"\"\n",
        "        ticker_symbol = row['tic']\n",
        "        if ticker_symbol in self.fundamental_data:\n",
        "            book_value_per_share = self.fundamental_data[ticker_symbol]['book_value_per_share']\n",
        "            sales_per_share = self.fundamental_data[ticker_symbol]['sales_per_share']\n",
        "            row['pb_ratio'] = row['close'] / book_value_per_share\n",
        "            row['ps_ratio'] = row['close'] / sales_per_share\n",
        "        else:\n",
        "            row['pb_ratio'] = float('nan')\n",
        "            row['ps_ratio'] = float('nan')\n",
        "        return row\n",
        "\n",
        "    def process_data(self):\n",
        "        \"\"\"\n",
        "        Process data including fetching, preprocessing, and calculating ratios.\n",
        "        \"\"\"\n",
        "        self.fetch_data()\n",
        "        self.preprocess_data()\n",
        "        self.fetch_fundamental_data()\n",
        "        self.df_new = self.df_new.apply(self.calculate_ratios, axis=1)\n",
        "        self.df_new['pb_ratio'] = np.abs(self.df_new['pb_ratio'])\n",
        "        #self.df_new.drop(['vix', 'turbulence'], axis=1, inplace=True)\n",
        "        list_ticker = self.df_new[\"tic\"].unique().tolist()\n",
        "        list_date = list(pd.date_range(self.df_new['date'].min(), self.df_new['date'].max()).astype(str))\n",
        "        combination = list(itertools.product(list_date, list_ticker))\n",
        "        processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"]).merge(self.df_new, on=[\"date\", \"tic\"],\n",
        "                                                                                    how=\"left\")\n",
        "        processed_full = processed_full[processed_full['date'].isin(self.df_new['date'])]\n",
        "        processed_full = processed_full.sort_values(['date', 'tic'])\n",
        "        processed_full.fillna(0, inplace=True)\n",
        "        df_normalized = self.df_new.copy()\n",
        "\n",
        "        def normalize_by_std(x):\n",
        "            if x.dtype == 'float64':\n",
        "                return x / x.std()\n",
        "            else:\n",
        "                return x\n",
        "\n",
        "        cols_to_normalize = df_normalized.columns.difference(['date', 'tic'])\n",
        "        df_normalized[cols_to_normalize] = self.df_new.groupby('tic')[cols_to_normalize].transform(normalize_by_std)\n",
        "\n",
        "        return processed_full, df_normalized"
      ],
      "metadata": {
        "id": "oHngc4MkVJmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funtion to add covariance for the StockPortfolio Environment and cleaning the preprocessed normalized data"
      ],
      "metadata": {
        "id": "MvQqf63_1fQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataframe(df_normalized):\n",
        "    df_normalized = df_normalized.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "    df_normalized = df_normalized.sort_values(['date', 'tic'], ignore_index=True)\n",
        "    df_normalized.index = df_normalized.date.factorize()[0]\n",
        "\n",
        "    cov_list_normalized = []\n",
        "    lookback = 252  # Look back is one year\n",
        "\n",
        "    # Calculate covariance matrix for each date\n",
        "    for i in range(lookback, len(df_normalized.index.unique())):\n",
        "        data_lookback = df_normalized.loc[i - lookback:i, :]\n",
        "        price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
        "        return_lookback = price_lookback.pct_change().dropna()\n",
        "        covs = return_lookback.cov().values\n",
        "        cov_list_normalized.append(covs)\n",
        "\n",
        "    # Create dataframe for covariance list\n",
        "    df_cov_normalized = pd.DataFrame({'date': df_normalized.date.unique()[lookback:], 'cov_list': cov_list_normalized})\n",
        "\n",
        "    # Merge covariance dataframe with original dataframe\n",
        "    df_normalized = df_normalized.merge(df_cov_normalized, on='date')\n",
        "    df_normalized = df_normalized.sort_values(['date', 'tic']).reset_index(drop=True)\n",
        "\n",
        "    return df_normalized"
      ],
      "metadata": {
        "id": "FcO8OyViVLmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##StockPortfolioEnv: The portfolio reallocation and reward calculation to take place here"
      ],
      "metadata": {
        "id": "N5mPW_gY18YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day=0):\n",
        "        # Initialize environment parameters\n",
        "        self.day = day\n",
        "        self.lookback = lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct = transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # Define action space as a Box\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(self.action_space,))\n",
        "\n",
        "        # Define observation space as a Box\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_space+len(self.tech_indicator_list), self.state_space))\n",
        "\n",
        "        # Get initial data for the environment\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "        # Create results directory if it doesn't exist\n",
        "        if not os.path.exists(\"results\"):\n",
        "          os.mkdir(\"results\")\n",
        "\n",
        "    def step(self, actions):\n",
        "        # Define the step function\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        if self.terminal:\n",
        "            # Calculate and plot cumulative rewards\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Plot rewards\n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Print statistics\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() != 0:\n",
        "                sharpe = (252**0.5)*df_daily_return['daily_return'].mean() / df_daily_return['daily_return'].std()\n",
        "                print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal, {}\n",
        "        else:\n",
        "            # Perform actions and update state\n",
        "            top_6_indices = np.argsort(actions)[-6:]\n",
        "            new_actions = np.zeros_like(actions)\n",
        "            top_6_weights = actions[top_6_indices]\n",
        "            total_weight = np.sum(top_6_weights)\n",
        "            if total_weight != 0:\n",
        "                top_6_weights /= total_weight\n",
        "            new_actions[top_6_indices] = top_6_weights\n",
        "            weights = new_actions\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "            self.reward = new_portfolio_value\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the environment\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Render the environment\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        # Perform softmax normalization\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator / denominator\n",
        "        return softmax_output\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        # Save asset memory\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        df_account_value = pd.DataFrame({'date':date_list, 'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # Save action memory\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        # Seed the environment\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        # Get the environment\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n"
      ],
      "metadata": {
        "id": "-gyFjHi_XrLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##StockTradingTrainer Class to train the 3 models, a2c (Just as a baseline), ddpg and ppo (since mentioned in the paper), Taking actions (weights) and daily return as the output"
      ],
      "metadata": {
        "id": "T-JNguM42RxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockTradingTrainer:\n",
        "    def __init__(self, df_train, df_test, model_params):\n",
        "        self.df_train = df_train\n",
        "        self.df_test = df_test\n",
        "        self.model_params = model_params\n",
        "\n",
        "    def train_models(self):\n",
        "        stock_dimension = len(self.df_train.tic.unique())\n",
        "        state_space = stock_dimension\n",
        "\n",
        "        env_kwargs = {\n",
        "            \"hmax\": 100,\n",
        "            \"initial_amount\": 1000000,\n",
        "            \"transaction_cost_pct\": 0.001,\n",
        "            \"state_space\": state_space,\n",
        "            \"stock_dim\": stock_dimension,\n",
        "            \"tech_indicator_list\": INDICATORS,\n",
        "            \"action_space\": stock_dimension,\n",
        "            \"reward_scaling\": 1e-4\n",
        "        }\n",
        "\n",
        "        # Create training environment\n",
        "        e_train_gym = StockPortfolioEnv(df=self.df_train, **env_kwargs)\n",
        "        env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "        # Train A2C model\n",
        "        agent = DRLAgent(env=env_train)\n",
        "        A2C_PARAMS = self.model_params.get(\"A2C_PARAMS\", {})\n",
        "        model_a2c = agent.get_model(model_name=\"a2c\", model_kwargs=A2C_PARAMS)\n",
        "        trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=60000)\n",
        "\n",
        "        # Train DDPG model\n",
        "        DDPG_PARAMS = self.model_params.get(\"DDPG_PARAMS\", {})\n",
        "        model_ddpg = agent.get_model(model_name=\"ddpg\", model_kwargs=DDPG_PARAMS)\n",
        "        trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=60000)\n",
        "\n",
        "        # Train PPO model\n",
        "        PPO_PARAMS = self.model_params.get(\"PPO_PARAMS\", {})\n",
        "        model_ppo = agent.get_model(model_name=\"ppo\", model_kwargs=PPO_PARAMS)\n",
        "        trained_ppo = agent.train_model(model=model_ppo, tb_log_name='ppo', total_timesteps=60000)\n",
        "\n",
        "        # Create testing environment\n",
        "        e_test_gym = StockPortfolioEnv(df=self.df_test, **env_kwargs)\n",
        "\n",
        "        # Make predictions for A2C model\n",
        "        df_daily_return_a2c, df_actions_a2c = DRLAgent.DRL_prediction(model=trained_a2c,\n",
        "                                                                       environment=e_test_gym)\n",
        "\n",
        "        # Make predictions for DDPG model\n",
        "        df_daily_return_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
        "                                                                         environment=e_test_gym)\n",
        "\n",
        "        # Make predictions for PPO model\n",
        "        df_daily_return_ppo, df_actions_ppo = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                                                                       environment=e_test_gym)\n",
        "\n",
        "        return (df_daily_return_a2c, df_actions_a2c,\n",
        "                df_daily_return_ddpg, df_actions_ddpg,\n",
        "                df_daily_return_ppo, df_actions_ppo)"
      ],
      "metadata": {
        "id": "NUqQdVlbYW_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MVO Class (used as a baseline)\n"
      ],
      "metadata": {
        "id": "MitnlVcu2pF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MVOAnalyzer:\n",
        "    def __init__(self, df_train, df_test):\n",
        "        \"\"\"\n",
        "        Initialize the MVOAnalyzer.\n",
        "\n",
        "        Args:\n",
        "        - df_train (DataFrame): DataFrame containing training data.\n",
        "        - df_test (DataFrame): DataFrame containing test data.\n",
        "        \"\"\"\n",
        "        self.df_train = df_train\n",
        "        self.df_test = df_test\n",
        "\n",
        "        # Initialize important DataFrames\n",
        "        self.df_mvo_train = self.df_train.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
        "        self.df_mvo_test = self.df_test.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
        "\n",
        "    def calculate_mvo_results(self):\n",
        "        \"\"\"\n",
        "        Calculate Mean-Variance Optimization (MVO) results.\n",
        "\n",
        "        Returns:\n",
        "        - df_mvo_results (DataFrame): DataFrame containing MVO daily portfolio values.\n",
        "        \"\"\"\n",
        "        def calculate_stock_return(df_prices):\n",
        "            num_days, num_assets = df_prices.shape\n",
        "            stock_return = np.zeros([num_days - 1, num_assets])\n",
        "\n",
        "            for j in range(num_assets):\n",
        "                for i in range(num_days - 1):\n",
        "                    stock_return[i, j] = ((df_prices.iloc[i + 1, j] - df_prices.iloc[i, j]) / df_prices.iloc[i, j]) * 100\n",
        "\n",
        "            return stock_return\n",
        "\n",
        "        portfolio_daily_returns = calculate_stock_return(self.df_mvo_train)\n",
        "        mean_returns = np.mean(portfolio_daily_returns, axis=0)\n",
        "        cov_returns = np.cov(portfolio_daily_returns, rowvar=False)\n",
        "\n",
        "        ef_mean = EfficientFrontier(mean_returns, cov_returns, weight_bounds=(0, 0.5))\n",
        "        raw_weights_mean = ef_mean.max_sharpe() # Maximize the Sharpe Ratio\n",
        "        cleaned_weights_mean = ef_mean.clean_weights() # Round the weights neatly\n",
        "        mvo_weights = 1_000_000 * np.array([weight for weight in cleaned_weights_mean.values()])\n",
        "\n",
        "        last_asset_prices = 1 / self.df_mvo_train.tail(1).values[0]\n",
        "        initial_testing_portfolio = np.multiply(mvo_weights, last_asset_prices)\n",
        "\n",
        "        mvo_daily_portfolio_value = self.df_mvo_test @ initial_testing_portfolio\n",
        "        df_mvo_results = pd.DataFrame(mvo_daily_portfolio_value, columns=[\"MVO\"])\n",
        "        df_mvo_results.index = pd.to_datetime(df_mvo_results.index)\n",
        "\n",
        "        return df_mvo_results\n"
      ],
      "metadata": {
        "id": "NqRNt8peaBkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The DOW30 tickers\n",
        "tickers = config_tickers.DOW_30_TICKER\n",
        "tickers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IJeo2ufaNDS",
        "outputId": "d245aac2-95ac-4961-caea-1c3fcb442d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AXP',\n",
              " 'AMGN',\n",
              " 'AAPL',\n",
              " 'BA',\n",
              " 'CAT',\n",
              " 'CSCO',\n",
              " 'CVX',\n",
              " 'GS',\n",
              " 'HD',\n",
              " 'HON',\n",
              " 'IBM',\n",
              " 'INTC',\n",
              " 'JNJ',\n",
              " 'KO',\n",
              " 'JPM',\n",
              " 'MCD',\n",
              " 'MMM',\n",
              " 'MRK',\n",
              " 'MSFT',\n",
              " 'NKE',\n",
              " 'PG',\n",
              " 'TRV',\n",
              " 'UNH',\n",
              " 'CRM',\n",
              " 'VZ',\n",
              " 'V',\n",
              " 'WBA',\n",
              " 'WMT',\n",
              " 'DIS',\n",
              " 'DOW']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In-Built Indicators\n",
        "INDICATORS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6QWgXNaVMr",
        "outputId": "003fc63b-a1d9-4c06-c988-68b40af842f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The whole analysis using the above classes are done below"
      ],
      "metadata": {
        "id": "WZfAS8Bc203a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_start = '2010-01-01'\n",
        "Train_end = '2019-12-31'\n",
        "Test_start = '2020-06-01'\n",
        "Test_end = '2021-06-01'\n",
        "processor = DataProcessor(Train_start,Test_start, Train_end, Test_end,config_tickers)\n",
        "processed_full, df_normalized = processor.process_data()"
      ],
      "metadata": {
        "id": "eK1U5Gw5aXJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_normalized = preprocess_dataframe(df_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARQBOvCXabjh",
        "outputId": "9be01e58-d08e-49c9-997c-0be59db3d14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = data_split(df_normalized,Train_start,Train_end)\n",
        "df_test = data_split(df_normalized,Test_start,Test_end)"
      ],
      "metadata": {
        "id": "8uqj3ZqGbUOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters\n",
        "model_params = {\n",
        "    \"A2C_PARAMS\": {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002},\n",
        "    \"DDPG_PARAMS\": {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.0001},\n",
        "    \"PPO_PARAMS\": {\"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "}\n",
        "\n",
        "trainer = StockTradingTrainer(df_train, df_test, model_params)\n",
        "(df_daily_return_a2c, df_actions_a2c,\n",
        " df_daily_return_ddpg, df_actions_ddpg,\n",
        " df_daily_return_ppo, df_actions_ppo) = trainer.train_models()\n",
        "\n",
        "\n",
        "\n",
        "mvo_analyzer = MVOAnalyzer(df_train, df_test)\n",
        "df_mvo_results = mvo_analyzer.calculate_mvo_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyJsNUc1cvRP",
        "outputId": "d4f7a48c-4f57-4778-8815-907d9dff0cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cpu device\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 300       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 1.5e+08   |\n",
            "|    reward             | 1220219.5 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 1.66e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 299       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 2.15e+08  |\n",
            "|    reward             | 1858306.6 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 3.38e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 263       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 2.8e+08   |\n",
            "|    reward             | 2229949.2 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.25e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 3.48e+08  |\n",
            "|    reward             | 3174801.2 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.08e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4065674.610543141\n",
            "Sharpe:  1.0859297881693977\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 263       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 1.26e+08  |\n",
            "|    reward             | 1077329.5 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 1.14e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 2e+08     |\n",
            "|    reward             | 1671390.1 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 3.08e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 2.5e+08   |\n",
            "|    reward             | 2001439.8 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 4.46e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 276       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 3.01e+08  |\n",
            "|    reward             | 2453215.8 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 6.46e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 279       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 4.08e+08  |\n",
            "|    reward             | 3337955.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 1.18e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3471108.8562864\n",
            "Sharpe:  0.9727338384398474\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 263       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 1.34e+08  |\n",
            "|    reward             | 1279609.4 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 1.67e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 265       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 2.4e+08   |\n",
            "|    reward             | 2130706.5 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 4.73e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 3.29e+08  |\n",
            "|    reward             | 2861121.8 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 8.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 4.93e+08  |\n",
            "|    reward             | 3933569.0 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 1.55e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5048465.536972271\n",
            "Sharpe:  1.2532077610360859\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 269        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | 2.38e-07   |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 1.22e+08   |\n",
            "|    reward             | 1022984.25 |\n",
            "|    std                | 0.99       |\n",
            "|    value_loss         | 1.07e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 1.94e+08  |\n",
            "|    reward             | 1535911.4 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 2.5e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 1.86e+08  |\n",
            "|    reward             | 1657628.2 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 2.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 2.58e+08  |\n",
            "|    reward             | 2249848.5 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 5.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 3.26e+08  |\n",
            "|    reward             | 2788384.2 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 7.8e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3152237.417188642\n",
            "Sharpe:  0.9209794048186583\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 1.43e+08  |\n",
            "|    reward             | 1196743.8 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 1.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1519526.6 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 2.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 2.42e+08  |\n",
            "|    reward             | 1991336.9 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 4.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 3.67e+08  |\n",
            "|    reward             | 3102346.8 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 1.01e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3664794.1038970468\n",
            "Sharpe:  1.038538698961368\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 270      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.7    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 1.2e+08  |\n",
            "|    reward             | 993238.0 |\n",
            "|    std                | 0.986    |\n",
            "|    value_loss         | 1.09e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 2.05e+08  |\n",
            "|    reward             | 1736903.8 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 3.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 2.71e+08  |\n",
            "|    reward             | 2077068.5 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 4.65e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 3.22e+08  |\n",
            "|    reward             | 3016433.2 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 9.11e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 4.91e+08  |\n",
            "|    reward             | 4378605.0 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 1.94e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4813113.724706938\n",
            "Sharpe:  1.2882851665128816\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 1.58e+08  |\n",
            "|    reward             | 1316528.9 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.82e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 2.49e+08  |\n",
            "|    reward             | 2026018.9 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 4.35e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 3.18e+08  |\n",
            "|    reward             | 2578575.5 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 7.12e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 4.73e+08  |\n",
            "|    reward             | 4061698.8 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 1.71e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4365931.144649706\n",
            "Sharpe:  1.2219560708595114\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 271        |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 58         |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0002     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | 1.39e+08   |\n",
            "|    reward             | 1003428.25 |\n",
            "|    std                | 0.983      |\n",
            "|    value_loss         | 1.1e+13    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 1.97e+08  |\n",
            "|    reward             | 1639165.1 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 2.96e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 2.56e+08  |\n",
            "|    reward             | 2220317.8 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 5.24e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 3.18e+08  |\n",
            "|    reward             | 2790463.2 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 7.94e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 4.16e+08  |\n",
            "|    reward             | 3622833.5 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 1.43e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3961987.313286528\n",
            "Sharpe:  1.1361838193330582\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 1.38e+08  |\n",
            "|    reward             | 1149846.6 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 1.45e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 2.12e+08  |\n",
            "|    reward             | 1691848.2 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.11e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.36e+08  |\n",
            "|    reward             | 2020460.5 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 4.28e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 73        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 3.36e+08  |\n",
            "|    reward             | 2812819.5 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 7.77e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3686959.454336497\n",
            "Sharpe:  1.0938963151596226\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 1.4e+08   |\n",
            "|    reward             | 1150986.0 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 1.43e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 76        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 2.16e+08  |\n",
            "|    reward             | 2073382.4 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 4.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 21500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 3.1e+08   |\n",
            "|    reward             | 2593054.5 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 7.1e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 3.68e+08  |\n",
            "|    reward             | 3270628.8 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 1.18e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 5.48e+08  |\n",
            "|    reward             | 4306971.5 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 1.9e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4749735.215782133\n",
            "Sharpe:  1.2751042514212785\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 1.52e+08  |\n",
            "|    reward             | 1223405.2 |\n",
            "|    std                | 0.978     |\n",
            "|    value_loss         | 1.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 2.31e+08  |\n",
            "|    reward             | 2046276.2 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 4.36e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 2.66e+08  |\n",
            "|    reward             | 2380018.8 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 5.86e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 89        |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 3.63e+08  |\n",
            "|    reward             | 3190931.8 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 1.04e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4131242.153791124\n",
            "Sharpe:  1.1894877993660486\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 1.37e+08  |\n",
            "|    reward             | 1134539.0 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 1.44e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 1.99e+08  |\n",
            "|    reward             | 1515252.0 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 2.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 2.2e+08   |\n",
            "|    reward             | 1817844.0 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 3.66e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 2.61e+08  |\n",
            "|    reward             | 2269015.8 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 5.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | 3.27e+08  |\n",
            "|    reward             | 2860119.0 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 8.42e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3110097.376810855\n",
            "Sharpe:  0.971185165249339\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 1.33e+08  |\n",
            "|    reward             | 1065462.6 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 1.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 102       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | 2.03e+08  |\n",
            "|    reward             | 1681797.5 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 2.93e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 2.69e+08  |\n",
            "|    reward             | 2271418.8 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 5.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 3.87e+08  |\n",
            "|    reward             | 2916930.8 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 9.35e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3613682.721224915\n",
            "Sharpe:  1.0927324242109564\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | 1.39e+08  |\n",
            "|    reward             | 1118344.9 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 1.23e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | 1.77e+08  |\n",
            "|    reward             | 1466468.4 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 2.35e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | 2.78e+08  |\n",
            "|    reward             | 2268546.8 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 5.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | 3.33e+08  |\n",
            "|    reward             | 2789862.8 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 8.18e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | 4e+08     |\n",
            "|    reward             | 3134830.0 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.04e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3703847.9427610845\n",
            "Sharpe:  1.0956196112357952\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 1.41e+08  |\n",
            "|    reward             | 1127874.5 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 1.39e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 1474377.5 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 2.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | 2.11e+08  |\n",
            "|    reward             | 1781766.2 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 3.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | 3.01e+08  |\n",
            "|    reward             | 2403032.8 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 6.63e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3062883.1401628843\n",
            "Sharpe:  0.9527916869997655\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 124       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 1.19e+08  |\n",
            "|    reward             | 1052565.8 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 1.13e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 6900      |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 34500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6899      |\n",
            "|    policy_loss        | 1.36e+08  |\n",
            "|    reward             | 1186831.5 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 1.45e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | 1.94e+08  |\n",
            "|    reward             | 1601119.0 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 2.76e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7100      |\n",
            "|    time_elapsed       | 129       |\n",
            "|    total_timesteps    | 35500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7099      |\n",
            "|    policy_loss        | 2.49e+08  |\n",
            "|    reward             | 2026961.1 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 4.38e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 131       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.3     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | 3.08e+08  |\n",
            "|    reward             | 2630257.5 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 7.63e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2947950.1931161336\n",
            "Sharpe:  0.9162497200075379\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 7300      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 36500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7299      |\n",
            "|    policy_loss        | 1.38e+08  |\n",
            "|    reward             | 1244171.1 |\n",
            "|    std                | 0.97      |\n",
            "|    value_loss         | 1.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | 1.69e+08  |\n",
            "|    reward             | 1634383.2 |\n",
            "|    std                | 0.969     |\n",
            "|    value_loss         | 2.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 137       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 2.33e+08  |\n",
            "|    reward             | 1985965.2 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 3.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | 3.7e+08   |\n",
            "|    reward             | 3358947.5 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 1.18e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4197399.767130199\n",
            "Sharpe:  1.1742471537568786\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7700      |\n",
            "|    time_elapsed       | 140       |\n",
            "|    total_timesteps    | 38500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7699      |\n",
            "|    policy_loss        | 1.19e+08  |\n",
            "|    reward             | 1051724.8 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 1.14e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 142       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 1.74e+08  |\n",
            "|    reward             | 1487800.4 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 2.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | 2.64e+08  |\n",
            "|    reward             | 2154831.8 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 4.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 146       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | 3.24e+08  |\n",
            "|    reward             | 2691059.8 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 7.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 4.01e+08  |\n",
            "|    reward             | 3195547.2 |\n",
            "|    std                | 0.967     |\n",
            "|    value_loss         | 1.09e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4165780.6170003503\n",
            "Sharpe:  1.1597497171109727\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 149       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | 1.53e+08  |\n",
            "|    reward             | 1267305.8 |\n",
            "|    std                | 0.966     |\n",
            "|    value_loss         | 1.65e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | 2.47e+08  |\n",
            "|    reward             | 2143885.5 |\n",
            "|    std                | 0.965     |\n",
            "|    value_loss         | 4.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 153       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | 3.21e+08  |\n",
            "|    reward             | 2769505.0 |\n",
            "|    std                | 0.965     |\n",
            "|    value_loss         | 8.61e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 155       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 6.11e+08  |\n",
            "|    reward             | 5234159.5 |\n",
            "|    std                | 0.964     |\n",
            "|    value_loss         | 2.76e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6340664.461032874\n",
            "Sharpe:  1.517654746091777\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 272      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 157      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | 7.53e+08 |\n",
            "|    reward             | 990646.1 |\n",
            "|    std                | 0.964    |\n",
            "|    value_loss         | 4.33e+14 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 272       |\n",
            "|    iterations         | 8700      |\n",
            "|    time_elapsed       | 159       |\n",
            "|    total_timesteps    | 43500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8699      |\n",
            "|    policy_loss        | 1.53e+08  |\n",
            "|    reward             | 1236054.5 |\n",
            "|    std                | 0.963     |\n",
            "|    value_loss         | 1.6e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 161       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 1.97e+08  |\n",
            "|    reward             | 1707122.8 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 2.93e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 162       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | 2.39e+08  |\n",
            "|    reward             | 2085305.1 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 4.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 164       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | 3.27e+08  |\n",
            "|    reward             | 2685522.2 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 8.42e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3422822.1620848672\n",
            "Sharpe:  1.0452124936085665\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 166       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 1.28e+08  |\n",
            "|    reward             | 1047936.5 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 1.22e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 168       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 2.1e+08   |\n",
            "|    reward             | 1604806.5 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 2.78e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 170       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 2.26e+08  |\n",
            "|    reward             | 2020434.4 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 4.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 171       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | 2.85e+08  |\n",
            "|    reward             | 2670764.5 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 7.03e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 173       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 3.57e+08  |\n",
            "|    reward             | 2990290.0 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 9.45e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3022610.959600199\n",
            "Sharpe:  0.938331565814835\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 175       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | 1.49e+08  |\n",
            "|    reward             | 1236410.0 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 1.48e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 176       |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | 2.33e+08  |\n",
            "|    reward             | 1939363.4 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 3.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 178       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | 2.22e+08  |\n",
            "|    reward             | 1949630.2 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 3.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 180       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | 2.97e+08  |\n",
            "|    reward             | 2542020.0 |\n",
            "|    std                | 0.959     |\n",
            "|    value_loss         | 6.57e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3350943.514455138\n",
            "Sharpe:  1.023166564393035\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 182       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | 1.36e+08  |\n",
            "|    reward             | 1141813.4 |\n",
            "|    std                | 0.958     |\n",
            "|    value_loss         | 1.4e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10100     |\n",
            "|    time_elapsed       | 184       |\n",
            "|    total_timesteps    | 50500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10099     |\n",
            "|    policy_loss        | 2.01e+08  |\n",
            "|    reward             | 1766250.1 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 3.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10200     |\n",
            "|    time_elapsed       | 186       |\n",
            "|    total_timesteps    | 51000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10199     |\n",
            "|    policy_loss        | 2.51e+08  |\n",
            "|    reward             | 1939019.1 |\n",
            "|    std                | 0.957     |\n",
            "|    value_loss         | 3.96e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 10300     |\n",
            "|    time_elapsed       | 187       |\n",
            "|    total_timesteps    | 51500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10299     |\n",
            "|    policy_loss        | 2.67e+08  |\n",
            "|    reward             | 2611685.5 |\n",
            "|    std                | 0.956     |\n",
            "|    value_loss         | 6.92e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 10400     |\n",
            "|    time_elapsed       | 189       |\n",
            "|    total_timesteps    | 52000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10399     |\n",
            "|    policy_loss        | 3.83e+08  |\n",
            "|    reward             | 3290915.8 |\n",
            "|    std                | 0.956     |\n",
            "|    value_loss         | 1.18e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3339261.4905451955\n",
            "Sharpe:  1.0101972103777868\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 10500     |\n",
            "|    time_elapsed       | 191       |\n",
            "|    total_timesteps    | 52500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10499     |\n",
            "|    policy_loss        | 1.59e+08  |\n",
            "|    reward             | 1283100.9 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 1.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10600     |\n",
            "|    time_elapsed       | 193       |\n",
            "|    total_timesteps    | 53000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10599     |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1688558.0 |\n",
            "|    std                | 0.955     |\n",
            "|    value_loss         | 3.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 195       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | 2.11e+08  |\n",
            "|    reward             | 1729008.5 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 3.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 10800     |\n",
            "|    time_elapsed       | 197       |\n",
            "|    total_timesteps    | 54000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10799     |\n",
            "|    policy_loss        | 3e+08     |\n",
            "|    reward             | 2491991.8 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 6.67e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2834839.844168423\n",
            "Sharpe:  0.8713665681891382\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 273      |\n",
            "|    iterations         | 10900    |\n",
            "|    time_elapsed       | 199      |\n",
            "|    total_timesteps    | 54500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -39.8    |\n",
            "|    explained_variance | 2.38e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 10899    |\n",
            "|    policy_loss        | 1.1e+08  |\n",
            "|    reward             | 981759.9 |\n",
            "|    std                | 0.953    |\n",
            "|    value_loss         | 1.01e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 11000     |\n",
            "|    time_elapsed       | 200       |\n",
            "|    total_timesteps    | 55000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 10999     |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1499563.6 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 2.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11100     |\n",
            "|    time_elapsed       | 202       |\n",
            "|    total_timesteps    | 55500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11099     |\n",
            "|    policy_loss        | 1.99e+08  |\n",
            "|    reward             | 1711546.2 |\n",
            "|    std                | 0.954     |\n",
            "|    value_loss         | 3.29e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11200     |\n",
            "|    time_elapsed       | 204       |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11199     |\n",
            "|    policy_loss        | 2.61e+08  |\n",
            "|    reward             | 2489194.8 |\n",
            "|    std                | 0.953     |\n",
            "|    value_loss         | 6.3e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 11300     |\n",
            "|    time_elapsed       | 206       |\n",
            "|    total_timesteps    | 56500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11299     |\n",
            "|    policy_loss        | 3.57e+08  |\n",
            "|    reward             | 2953783.0 |\n",
            "|    std                | 0.953     |\n",
            "|    value_loss         | 9.01e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2864441.1601118674\n",
            "Sharpe:  0.876517917574622\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 11400     |\n",
            "|    time_elapsed       | 208       |\n",
            "|    total_timesteps    | 57000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11399     |\n",
            "|    policy_loss        | 1.37e+08  |\n",
            "|    reward             | 1183102.1 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 1.43e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 210       |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 2.13e+08  |\n",
            "|    reward             | 1728758.8 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 3.2e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11600     |\n",
            "|    time_elapsed       | 211       |\n",
            "|    total_timesteps    | 58000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11599     |\n",
            "|    policy_loss        | 2.24e+08  |\n",
            "|    reward             | 1896895.9 |\n",
            "|    std                | 0.952     |\n",
            "|    value_loss         | 3.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11700     |\n",
            "|    time_elapsed       | 213       |\n",
            "|    total_timesteps    | 58500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11699     |\n",
            "|    policy_loss        | 3.15e+08  |\n",
            "|    reward             | 2694429.5 |\n",
            "|    std                | 0.951     |\n",
            "|    value_loss         | 7.37e+13  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2888497.3392494484\n",
            "Sharpe:  0.8872108211314599\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11800     |\n",
            "|    time_elapsed       | 215       |\n",
            "|    total_timesteps    | 59000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11799     |\n",
            "|    policy_loss        | 1.18e+08  |\n",
            "|    reward             | 1012539.5 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 1.05e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 11900     |\n",
            "|    time_elapsed       | 217       |\n",
            "|    total_timesteps    | 59500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11899     |\n",
            "|    policy_loss        | 1.96e+08  |\n",
            "|    reward             | 1538497.0 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 2.64e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 273       |\n",
            "|    iterations         | 12000     |\n",
            "|    time_elapsed       | 219       |\n",
            "|    total_timesteps    | 60000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 11999     |\n",
            "|    policy_loss        | 2.29e+08  |\n",
            "|    reward             | 2063057.0 |\n",
            "|    std                | 0.95      |\n",
            "|    value_loss         | 4.41e+13  |\n",
            "-------------------------------------\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.0001}\n",
            "Using cpu device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3448926.75442139\n",
            "Sharpe:  0.9889665965356537\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 17        |\n",
            "|    time_elapsed    | 506       |\n",
            "|    total_timesteps | 9052      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.33e+07 |\n",
            "|    critic_loss     | 6.18e+11  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 8951      |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 17        |\n",
            "|    time_elapsed    | 1060      |\n",
            "|    total_timesteps | 18104     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.4e+07  |\n",
            "|    critic_loss     | 1.31e+12  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 18003     |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 1616      |\n",
            "|    total_timesteps | 27156     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.05e+08 |\n",
            "|    critic_loss     | 2.21e+12  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 27055     |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 2193      |\n",
            "|    total_timesteps | 36208     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.25e+08 |\n",
            "|    critic_loss     | 2.5e+12   |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 36107     |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 2774      |\n",
            "|    total_timesteps | 45260     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.43e+08 |\n",
            "|    critic_loss     | 2.73e+12  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 45159     |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 24        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 3440      |\n",
            "|    total_timesteps | 54312     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.55e+08 |\n",
            "|    critic_loss     | 3.28e+12  |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 54211     |\n",
            "|    reward          | 3096736.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3096735.8838337953\n",
            "Sharpe:  0.8687282200336366\n",
            "=================================\n",
            "{'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cpu device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 400       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4119024.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4529207.536915745\n",
            "Sharpe:  1.1884172393702659\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 345       |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 11        |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 8.97e+14  |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | -1.98e-06 |\n",
            "|    reward               | 2633459.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.65e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3248284.8104608348\n",
            "Sharpe:  0.93885593022586\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 316       |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 19        |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.21e+14  |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -2.72e-06 |\n",
            "|    reward               | 2636281.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.23e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3811466.253314112\n",
            "Sharpe:  1.0630846792053539\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 313       |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 26        |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.54e+14  |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | -2.38e-06 |\n",
            "|    reward               | 2037016.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.16e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4502251.550919579\n",
            "Sharpe:  1.1729317022641494\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 305       |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 33        |\n",
            "|    total_timesteps      | 10240     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.39e+14  |\n",
            "|    n_updates            | 40        |\n",
            "|    policy_gradient_loss | -3.47e-06 |\n",
            "|    reward               | 1432577.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.3e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3442251.272622219\n",
            "Sharpe:  0.9997360639103652\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 41        |\n",
            "|    total_timesteps      | 12288     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.23e+14  |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -1.42e-06 |\n",
            "|    reward               | 1824955.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.34e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3487932.949378724\n",
            "Sharpe:  1.001673676457818\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 299       |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 47        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.56e+14  |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | -1.83e-06 |\n",
            "|    reward               | 1441033.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.07e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3369692.5040861405\n",
            "Sharpe:  0.957280378296828\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 293       |\n",
            "|    iterations           | 8         |\n",
            "|    time_elapsed         | 55        |\n",
            "|    total_timesteps      | 16384     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6e+14     |\n",
            "|    n_updates            | 70        |\n",
            "|    policy_gradient_loss | -2.22e-06 |\n",
            "|    reward               | 1223227.9 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.25e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3820700.675550231\n",
            "Sharpe:  1.0468958782682196\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 295       |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 62        |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.4e+14   |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | -2.37e-06 |\n",
            "|    reward               | 1212382.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.16e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3896869.8847589074\n",
            "Sharpe:  1.0698973133946734\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 293       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 69        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 7.47e+14  |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -1.66e-06 |\n",
            "|    reward               | 1059268.6 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.4e+15   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 294       |\n",
            "|    iterations           | 11        |\n",
            "|    time_elapsed         | 76        |\n",
            "|    total_timesteps      | 22528     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 7.88e+14  |\n",
            "|    n_updates            | 100       |\n",
            "|    policy_gradient_loss | -1.4e-06  |\n",
            "|    reward               | 2921346.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.72e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3162485.728571833\n",
            "Sharpe:  0.9178659127324112\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 293       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 83        |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.52e+14  |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | -2.19e-06 |\n",
            "|    reward               | 3435825.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.09e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4273967.191243958\n",
            "Sharpe:  1.1473210645219718\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 292       |\n",
            "|    iterations           | 13        |\n",
            "|    time_elapsed         | 91        |\n",
            "|    total_timesteps      | 26624     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.18e+14  |\n",
            "|    n_updates            | 120       |\n",
            "|    policy_gradient_loss | -3.5e-06  |\n",
            "|    reward               | 2555251.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.28e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3237384.335881659\n",
            "Sharpe:  0.9548470441629013\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 293       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 97        |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.07e+14  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -3.23e-06 |\n",
            "|    reward               | 2371596.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.18e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3431202.5248072944\n",
            "Sharpe:  0.9925391449791838\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 292       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 105       |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.25e+14  |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -2.61e-06 |\n",
            "|    reward               | 2046879.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.23e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4641849.164098088\n",
            "Sharpe:  1.191552218980618\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 293       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 111       |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.74e+14  |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -2.96e-06 |\n",
            "|    reward               | 2328786.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.2e+15   |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4463239.202218822\n",
            "Sharpe:  1.199401485971325\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 292       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 119       |\n",
            "|    total_timesteps      | 34816     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 9.7e+14   |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | -2e-06    |\n",
            "|    reward               | 1622310.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.74e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2882990.9381422107\n",
            "Sharpe:  0.8528589702994881\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 291       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 126       |\n",
            "|    total_timesteps      | 36864     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 7.51e+14  |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | -1.69e-06 |\n",
            "|    reward               | 1501188.1 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.67e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2852598.4603767614\n",
            "Sharpe:  0.8419037438650468\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 292       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 133       |\n",
            "|    total_timesteps      | 38912     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.59e+14  |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -2.55e-06 |\n",
            "|    reward               | 1318781.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.11e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5412809.4132681405\n",
            "Sharpe:  1.3056066590983029\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 291        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 140        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | -2.38e-07  |\n",
            "|    learning_rate        | 0.0002     |\n",
            "|    loss                 | 4.75e+14   |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -2.03e-06  |\n",
            "|    reward               | 1037982.06 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 1e+15      |\n",
            "----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4639266.223006819\n",
            "Sharpe:  1.2012667954853722\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 291        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 147        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0        |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.1      |\n",
            "|    explained_variance   | 5.96e-08   |\n",
            "|    learning_rate        | 0.0002     |\n",
            "|    loss                 | 1.26e+15   |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -1.67e-06  |\n",
            "|    reward               | 1007005.56 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 2.3e+15    |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 291       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 154       |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 1.11e+15  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -1.89e-06 |\n",
            "|    reward               | 2536760.8 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.01e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3353807.346247198\n",
            "Sharpe:  0.9650584178273949\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 292       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 161       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 2.38e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 3.78e+14  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -2.4e-06  |\n",
            "|    reward               | 2503388.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.23e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3353859.29736352\n",
            "Sharpe:  0.9682005730070965\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 289       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 169       |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 4.76e+14  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -2.2e-06  |\n",
            "|    reward               | 2426818.2 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 8.83e+14  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3904412.3125171615\n",
            "Sharpe:  1.0777184509215092\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 287       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 178       |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.89e+14  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -2.83e-06 |\n",
            "|    reward               | 2442375.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.08e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5034757.164624745\n",
            "Sharpe:  1.2627923258595355\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 287       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 185       |\n",
            "|    total_timesteps      | 53248     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 7.73e+14  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | -1.72e-06 |\n",
            "|    reward               | 1638454.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.48e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:3635050.311688031\n",
            "Sharpe:  1.0343472075711941\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 286       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 193       |\n",
            "|    total_timesteps      | 55296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 9.69e+14  |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -1.92e-06 |\n",
            "|    reward               | 2385329.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.78e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5498547.252270789\n",
            "Sharpe:  1.34275502854482\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 285       |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 200       |\n",
            "|    total_timesteps      | 57344     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 6.04e+14  |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | -2.74e-06 |\n",
            "|    reward               | 1663812.4 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.17e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:2927236.7114092484\n",
            "Sharpe:  0.8607443788648939\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 285       |\n",
            "|    iterations           | 29        |\n",
            "|    time_elapsed         | 208       |\n",
            "|    total_timesteps      | 59392     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 1.17e+15  |\n",
            "|    n_updates            | 280       |\n",
            "|    policy_gradient_loss | -1.57e-06 |\n",
            "|    reward               | 1659076.0 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.37e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4639476.806922367\n",
            "Sharpe:  1.2105980954915934\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 284       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 215       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -41.1     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0002    |\n",
            "|    loss                 | 5.14e+14  |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | -2.78e-06 |\n",
            "|    reward               | 1168942.5 |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 1.04e+15  |\n",
            "---------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1392508.4756360394\n",
            "Sharpe:  1.9339251597229827\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1524121.1355317323\n",
            "Sharpe:  2.3479962519881243\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1494359.002181901\n",
            "Sharpe:  2.350071233038423\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_symbol = '^DJI'\n",
        "start_date = '2020-06-01'\n",
        "end_date = '2021-05-28'\n",
        "\n",
        "djia_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
        "djia_data['daily_Return'] = djia_data['Close'].pct_change()\n",
        "djia_data = djia_data[['daily_Return']].reset_index()\n",
        "djia_data.fillna(0 ,inplace= True)\n",
        "djia_data.rename(columns={'Date': 'date', 'daily_Return': 'daily_return'}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5VElngYczKu",
        "outputId": "5ddbb369-e20c-4fd8-c060-619297d84a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_daily_return_a2c['date'] = pd.to_datetime(df_daily_return_a2c['date'])\n",
        "df_daily_return_ddpg['date'] = pd.to_datetime(df_daily_return_ddpg['date'])\n",
        "df_daily_return_ppo['date'] = pd.to_datetime(df_daily_return_ppo['date'])\n",
        "djia_data['date'] = pd.to_datetime(djia_data['date'])\n",
        "\n",
        "merged_df = df_daily_return_a2c.merge(df_daily_return_ddpg, on='date', suffixes=('_a2c', '_ddpg'))\n",
        "merged_df = merged_df.merge(df_daily_return_ppo, on='date')\n",
        "final_df = merged_df.merge(djia_data, on='date')\n",
        "final_df.rename(columns={'daily_return_x': 'daily_return_ppo', 'daily_return_y': 'daily_return_DJIA'}, inplace=True)"
      ],
      "metadata": {
        "id": "4R4BEIopwbSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_investment = 1000000\n",
        "final_df['cumulative_return_a2c'] = (1 + final_df['daily_return_a2c']).cumprod() * initial_investment\n",
        "final_df['cumulative_return_ddpg'] = (1 + final_df['daily_return_ddpg']).cumprod() * initial_investment\n",
        "final_df['cumulative_return_ppo'] = (1 + final_df['daily_return_ppo']).cumprod() * initial_investment\n",
        "final_df['cumulative_return_djia'] = (1 + final_df['daily_return_DJIA']).cumprod() * initial_investment\n",
        "df_mvo_results_reset = df_mvo_results.reset_index()\n",
        "final_df['cumulative_return_mvo']=df_mvo_results_reset['MVO']"
      ],
      "metadata": {
        "id": "VSdn7RZew4wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "QjWA96jQxMJT",
        "outputId": "4d9ca889-3bb6-41d8-fe23-dfb16098aa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_dataframe_summarizer.py:73: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          date  daily_return_a2c  daily_return_ddpg  daily_return_ppo  \\\n",
              "0   2020-06-01          0.000000           0.000000          0.000000   \n",
              "1   2020-06-02          0.011029           0.005023          0.005020   \n",
              "2   2020-06-03          0.014913           0.018808          0.013838   \n",
              "3   2020-06-04         -0.003212           0.002729         -0.000853   \n",
              "4   2020-06-05          0.036635           0.017579          0.021776   \n",
              "..         ...               ...                ...               ...   \n",
              "246 2021-05-21         -0.000801           0.003840          0.001422   \n",
              "247 2021-05-24          0.003938           0.007905          0.007044   \n",
              "248 2021-05-25         -0.003254          -0.000063         -0.000106   \n",
              "249 2021-05-26          0.001484           0.003958         -0.007786   \n",
              "250 2021-05-27          0.000855           0.004768          0.001937   \n",
              "\n",
              "     daily_return_DJIA  cumulative_return_a2c  cumulative_return_ddpg  \\\n",
              "0             0.000000           1.000000e+06            1.000000e+06   \n",
              "1             0.010506           1.011029e+06            1.005023e+06   \n",
              "2             0.020481           1.026107e+06            1.023925e+06   \n",
              "3             0.000454           1.022811e+06            1.026719e+06   \n",
              "4             0.031549           1.060282e+06            1.044768e+06   \n",
              "..                 ...                    ...                     ...   \n",
              "246           0.003629           1.388324e+06            1.499153e+06   \n",
              "247           0.005441           1.393791e+06            1.511004e+06   \n",
              "248          -0.002370           1.389257e+06            1.510909e+06   \n",
              "249           0.000309           1.391318e+06            1.516889e+06   \n",
              "250           0.004125           1.392508e+06            1.524121e+06   \n",
              "\n",
              "     cumulative_return_ppo  cumulative_return_djia  cumulative_return_mvo  \n",
              "0             1.000000e+06            1.000000e+06           1.072701e+06  \n",
              "1             1.005020e+06            1.010506e+06           1.083867e+06  \n",
              "2             1.018927e+06            1.031202e+06           1.084865e+06  \n",
              "3             1.018058e+06            1.031670e+06           1.068941e+06  \n",
              "4             1.040227e+06            1.064218e+06           1.103846e+06  \n",
              "..                     ...                     ...                    ...  \n",
              "246           1.492818e+06            1.342799e+06           1.402433e+06  \n",
              "247           1.503334e+06            1.350106e+06           1.408603e+06  \n",
              "248           1.503174e+06            1.346906e+06           1.412198e+06  \n",
              "249           1.491470e+06            1.347322e+06           1.409402e+06  \n",
              "250           1.494359e+06            1.352880e+06           1.407939e+06  \n",
              "\n",
              "[251 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-750a6505-784d-49a9-ac92-e7abca4f92f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return_a2c</th>\n",
              "      <th>daily_return_ddpg</th>\n",
              "      <th>daily_return_ppo</th>\n",
              "      <th>daily_return_DJIA</th>\n",
              "      <th>cumulative_return_a2c</th>\n",
              "      <th>cumulative_return_ddpg</th>\n",
              "      <th>cumulative_return_ppo</th>\n",
              "      <th>cumulative_return_djia</th>\n",
              "      <th>cumulative_return_mvo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>1.072701e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-02</td>\n",
              "      <td>0.011029</td>\n",
              "      <td>0.005023</td>\n",
              "      <td>0.005020</td>\n",
              "      <td>0.010506</td>\n",
              "      <td>1.011029e+06</td>\n",
              "      <td>1.005023e+06</td>\n",
              "      <td>1.005020e+06</td>\n",
              "      <td>1.010506e+06</td>\n",
              "      <td>1.083867e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-03</td>\n",
              "      <td>0.014913</td>\n",
              "      <td>0.018808</td>\n",
              "      <td>0.013838</td>\n",
              "      <td>0.020481</td>\n",
              "      <td>1.026107e+06</td>\n",
              "      <td>1.023925e+06</td>\n",
              "      <td>1.018927e+06</td>\n",
              "      <td>1.031202e+06</td>\n",
              "      <td>1.084865e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-04</td>\n",
              "      <td>-0.003212</td>\n",
              "      <td>0.002729</td>\n",
              "      <td>-0.000853</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>1.022811e+06</td>\n",
              "      <td>1.026719e+06</td>\n",
              "      <td>1.018058e+06</td>\n",
              "      <td>1.031670e+06</td>\n",
              "      <td>1.068941e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-05</td>\n",
              "      <td>0.036635</td>\n",
              "      <td>0.017579</td>\n",
              "      <td>0.021776</td>\n",
              "      <td>0.031549</td>\n",
              "      <td>1.060282e+06</td>\n",
              "      <td>1.044768e+06</td>\n",
              "      <td>1.040227e+06</td>\n",
              "      <td>1.064218e+06</td>\n",
              "      <td>1.103846e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>2021-05-21</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>0.001422</td>\n",
              "      <td>0.003629</td>\n",
              "      <td>1.388324e+06</td>\n",
              "      <td>1.499153e+06</td>\n",
              "      <td>1.492818e+06</td>\n",
              "      <td>1.342799e+06</td>\n",
              "      <td>1.402433e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2021-05-24</td>\n",
              "      <td>0.003938</td>\n",
              "      <td>0.007905</td>\n",
              "      <td>0.007044</td>\n",
              "      <td>0.005441</td>\n",
              "      <td>1.393791e+06</td>\n",
              "      <td>1.511004e+06</td>\n",
              "      <td>1.503334e+06</td>\n",
              "      <td>1.350106e+06</td>\n",
              "      <td>1.408603e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>2021-05-25</td>\n",
              "      <td>-0.003254</td>\n",
              "      <td>-0.000063</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>-0.002370</td>\n",
              "      <td>1.389257e+06</td>\n",
              "      <td>1.510909e+06</td>\n",
              "      <td>1.503174e+06</td>\n",
              "      <td>1.346906e+06</td>\n",
              "      <td>1.412198e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2021-05-26</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>0.003958</td>\n",
              "      <td>-0.007786</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>1.391318e+06</td>\n",
              "      <td>1.516889e+06</td>\n",
              "      <td>1.491470e+06</td>\n",
              "      <td>1.347322e+06</td>\n",
              "      <td>1.409402e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2021-05-27</td>\n",
              "      <td>0.000855</td>\n",
              "      <td>0.004768</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.004125</td>\n",
              "      <td>1.392508e+06</td>\n",
              "      <td>1.524121e+06</td>\n",
              "      <td>1.494359e+06</td>\n",
              "      <td>1.352880e+06</td>\n",
              "      <td>1.407939e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>251 rows  10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-750a6505-784d-49a9-ac92-e7abca4f92f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-750a6505-784d-49a9-ac92-e7abca4f92f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-750a6505-784d-49a9-ac92-e7abca4f92f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee995d34-54b6-4eb8-9df5-8fddc97d0b71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee995d34-54b6-4eb8-9df5-8fddc97d0b71')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee995d34-54b6-4eb8-9df5-8fddc97d0b71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_424e6da0-6788-4ea2-b7b6-54244fa4ea8d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_424e6da0-6788-4ea2-b7b6-54244fa4ea8d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df",
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 251,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-06-01 00:00:00\",\n        \"max\": \"2021-05-27 00:00:00\",\n        \"num_unique_values\": 251,\n        \"samples\": [\n          \"2021-01-11 00:00:00\",\n          \"2020-06-09 00:00:00\",\n          \"2021-01-25 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_a2c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011366774088569901,\n        \"min\": -0.06526498765083642,\n        \"max\": 0.036635246655369755,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          -0.006724351568888879,\n          -0.002491373533558602,\n          0.004427403012485999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_ddpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01183344043820428,\n        \"min\": -0.0630813090292628,\n        \"max\": 0.04922622628012386,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          -0.002781499834784483,\n          -0.015325684143753484,\n          -0.007550492755660357\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_ppo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011248188463356644,\n        \"min\": -0.07055659564123279,\n        \"max\": 0.0286724458528311,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1.2966925569110827e-05,\n          -0.023212966301838663,\n          0.005516921023034649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_DJIA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010991598215574237,\n        \"min\": -0.0689818816654757,\n        \"max\": 0.031548810028795504,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          -0.002870967075386366,\n          -0.0108854594598079,\n          -0.0011930345533908149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cumulative_return_a2c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119185.75204004542,\n        \"min\": 988315.9928756636,\n        \"max\": 1432906.1346230975,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1236003.6121743398,\n          1072953.131556852,\n          1272189.5985345545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cumulative_return_ddpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 166375.4195214657,\n        \"min\": 969505.6567758106,\n        \"max\": 1524121.1355317326,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1374989.7448381435,\n          1042544.4308665437,\n          1350992.2609077292\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cumulative_return_ppo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179911.5521872407,\n        \"min\": 936857.0572784882,\n        \"max\": 1509638.9489269848,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1382260.4033780599,\n          1034853.6996465483,\n          1344372.7083976592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cumulative_return_djia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105710.39569528987,\n        \"min\": 981963.949058552,\n        \"max\": 1365171.1503533248,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1217219.4574801747,\n          1070550.7309933673,\n          1215308.1948385404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cumulative_return_mvo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96682.8702404891,\n        \"min\": 1040800.9556542863,\n        \"max\": 1453106.4824888231,\n        \"num_unique_values\": 251,\n        \"samples\": [\n          1268593.2745452293,\n          1107675.0003335744,\n          1273634.5682713003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=final_df['date'], y=final_df['cumulative_return_a2c'], mode='lines', name='A2C'))\n",
        "fig.add_trace(go.Scatter(x=final_df['date'], y=final_df['cumulative_return_ddpg'], mode='lines', name='DDPG'))\n",
        "fig.add_trace(go.Scatter(x=final_df['date'], y=final_df['cumulative_return_ppo'], mode='lines', name='PPO'))\n",
        "fig.add_trace(go.Scatter(x=final_df['date'], y=final_df['cumulative_return_djia'], mode='lines', name='DJIA'))\n",
        "fig.add_trace(go.Scatter(x=final_df['date'], y=final_df['cumulative_return_mvo'], mode='lines', name='MVO'))\n",
        "fig.update_layout(title='Cumulative Returns',\n",
        "                   xaxis_title='Date',\n",
        "                   yaxis_title='Cumulative Return',\n",
        "                   legend_title='Strategy')\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "WVhei3dZ0peT",
        "outputId": "77dcee81-6590-4261-a44d-5844453beb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9591aea6-f828-4f6e-8f35-97b63c78531f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9591aea6-f828-4f6e-8f35-97b63c78531f\")) {                    Plotly.newPlot(                        \"9591aea6-f828-4f6e-8f35-97b63c78531f\",                        [{\"mode\":\"lines\",\"name\":\"A2C\",\"x\":[\"2020-06-01T00:00:00\",\"2020-06-02T00:00:00\",\"2020-06-03T00:00:00\",\"2020-06-04T00:00:00\",\"2020-06-05T00:00:00\",\"2020-06-08T00:00:00\",\"2020-06-09T00:00:00\",\"2020-06-10T00:00:00\",\"2020-06-11T00:00:00\",\"2020-06-12T00:00:00\",\"2020-06-15T00:00:00\",\"2020-06-16T00:00:00\",\"2020-06-17T00:00:00\",\"2020-06-18T00:00:00\",\"2020-06-19T00:00:00\",\"2020-06-22T00:00:00\",\"2020-06-23T00:00:00\",\"2020-06-24T00:00:00\",\"2020-06-25T00:00:00\",\"2020-06-26T00:00:00\",\"2020-06-29T00:00:00\",\"2020-06-30T00:00:00\",\"2020-07-01T00:00:00\",\"2020-07-02T00:00:00\",\"2020-07-06T00:00:00\",\"2020-07-07T00:00:00\",\"2020-07-08T00:00:00\",\"2020-07-09T00:00:00\",\"2020-07-10T00:00:00\",\"2020-07-13T00:00:00\",\"2020-07-14T00:00:00\",\"2020-07-15T00:00:00\",\"2020-07-16T00:00:00\",\"2020-07-17T00:00:00\",\"2020-07-20T00:00:00\",\"2020-07-21T00:00:00\",\"2020-07-22T00:00:00\",\"2020-07-23T00:00:00\",\"2020-07-24T00:00:00\",\"2020-07-27T00:00:00\",\"2020-07-28T00:00:00\",\"2020-07-29T00:00:00\",\"2020-07-30T00:00:00\",\"2020-07-31T00:00:00\",\"2020-08-03T00:00:00\",\"2020-08-04T00:00:00\",\"2020-08-05T00:00:00\",\"2020-08-06T00:00:00\",\"2020-08-07T00:00:00\",\"2020-08-10T00:00:00\",\"2020-08-11T00:00:00\",\"2020-08-12T00:00:00\",\"2020-08-13T00:00:00\",\"2020-08-14T00:00:00\",\"2020-08-17T00:00:00\",\"2020-08-18T00:00:00\",\"2020-08-19T00:00:00\",\"2020-08-20T00:00:00\",\"2020-08-21T00:00:00\",\"2020-08-24T00:00:00\",\"2020-08-25T00:00:00\",\"2020-08-26T00:00:00\",\"2020-08-27T00:00:00\",\"2020-08-28T00:00:00\",\"2020-08-31T00:00:00\",\"2020-09-01T00:00:00\",\"2020-09-02T00:00:00\",\"2020-09-03T00:00:00\",\"2020-09-04T00:00:00\",\"2020-09-08T00:00:00\",\"2020-09-09T00:00:00\",\"2020-09-10T00:00:00\",\"2020-09-11T00:00:00\",\"2020-09-14T00:00:00\",\"2020-09-15T00:00:00\",\"2020-09-16T00:00:00\",\"2020-09-17T00:00:00\",\"2020-09-18T00:00:00\",\"2020-09-21T00:00:00\",\"2020-09-22T00:00:00\",\"2020-09-23T00:00:00\",\"2020-09-24T00:00:00\",\"2020-09-25T00:00:00\",\"2020-09-28T00:00:00\",\"2020-09-29T00:00:00\",\"2020-09-30T00:00:00\",\"2020-10-01T00:00:00\",\"2020-10-02T00:00:00\",\"2020-10-05T00:00:00\",\"2020-10-06T00:00:00\",\"2020-10-07T00:00:00\",\"2020-10-08T00:00:00\",\"2020-10-09T00:00:00\",\"2020-10-12T00:00:00\",\"2020-10-13T00:00:00\",\"2020-10-14T00:00:00\",\"2020-10-15T00:00:00\",\"2020-10-16T00:00:00\",\"2020-10-19T00:00:00\",\"2020-10-20T00:00:00\",\"2020-10-21T00:00:00\",\"2020-10-22T00:00:00\",\"2020-10-23T00:00:00\",\"2020-10-26T00:00:00\",\"2020-10-27T00:00:00\",\"2020-10-28T00:00:00\",\"2020-10-29T00:00:00\",\"2020-10-30T00:00:00\",\"2020-11-02T00:00:00\",\"2020-11-03T00:00:00\",\"2020-11-04T00:00:00\",\"2020-11-05T00:00:00\",\"2020-11-06T00:00:00\",\"2020-11-09T00:00:00\",\"2020-11-10T00:00:00\",\"2020-11-11T00:00:00\",\"2020-11-12T00:00:00\",\"2020-11-13T00:00:00\",\"2020-11-16T00:00:00\",\"2020-11-17T00:00:00\",\"2020-11-18T00:00:00\",\"2020-11-19T00:00:00\",\"2020-11-20T00:00:00\",\"2020-11-23T00:00:00\",\"2020-11-24T00:00:00\",\"2020-11-25T00:00:00\",\"2020-11-27T00:00:00\",\"2020-11-30T00:00:00\",\"2020-12-01T00:00:00\",\"2020-12-02T00:00:00\",\"2020-12-03T00:00:00\",\"2020-12-04T00:00:00\",\"2020-12-07T00:00:00\",\"2020-12-08T00:00:00\",\"2020-12-09T00:00:00\",\"2020-12-10T00:00:00\",\"2020-12-11T00:00:00\",\"2020-12-14T00:00:00\",\"2020-12-15T00:00:00\",\"2020-12-16T00:00:00\",\"2020-12-17T00:00:00\",\"2020-12-18T00:00:00\",\"2020-12-21T00:00:00\",\"2020-12-22T00:00:00\",\"2020-12-23T00:00:00\",\"2020-12-24T00:00:00\",\"2020-12-28T00:00:00\",\"2020-12-29T00:00:00\",\"2020-12-30T00:00:00\",\"2020-12-31T00:00:00\",\"2021-01-04T00:00:00\",\"2021-01-05T00:00:00\",\"2021-01-06T00:00:00\",\"2021-01-07T00:00:00\",\"2021-01-08T00:00:00\",\"2021-01-11T00:00:00\",\"2021-01-12T00:00:00\",\"2021-01-13T00:00:00\",\"2021-01-14T00:00:00\",\"2021-01-15T00:00:00\",\"2021-01-19T00:00:00\",\"2021-01-20T00:00:00\",\"2021-01-21T00:00:00\",\"2021-01-22T00:00:00\",\"2021-01-25T00:00:00\",\"2021-01-26T00:00:00\",\"2021-01-27T00:00:00\",\"2021-01-28T00:00:00\",\"2021-01-29T00:00:00\",\"2021-02-01T00:00:00\",\"2021-02-02T00:00:00\",\"2021-02-03T00:00:00\",\"2021-02-04T00:00:00\",\"2021-02-05T00:00:00\",\"2021-02-08T00:00:00\",\"2021-02-09T00:00:00\",\"2021-02-10T00:00:00\",\"2021-02-11T00:00:00\",\"2021-02-12T00:00:00\",\"2021-02-16T00:00:00\",\"2021-02-17T00:00:00\",\"2021-02-18T00:00:00\",\"2021-02-19T00:00:00\",\"2021-02-22T00:00:00\",\"2021-02-23T00:00:00\",\"2021-02-24T00:00:00\",\"2021-02-25T00:00:00\",\"2021-02-26T00:00:00\",\"2021-03-01T00:00:00\",\"2021-03-02T00:00:00\",\"2021-03-03T00:00:00\",\"2021-03-04T00:00:00\",\"2021-03-05T00:00:00\",\"2021-03-08T00:00:00\",\"2021-03-09T00:00:00\",\"2021-03-10T00:00:00\",\"2021-03-11T00:00:00\",\"2021-03-12T00:00:00\",\"2021-03-15T00:00:00\",\"2021-03-16T00:00:00\",\"2021-03-17T00:00:00\",\"2021-03-18T00:00:00\",\"2021-03-19T00:00:00\",\"2021-03-22T00:00:00\",\"2021-03-23T00:00:00\",\"2021-03-24T00:00:00\",\"2021-03-25T00:00:00\",\"2021-03-26T00:00:00\",\"2021-03-29T00:00:00\",\"2021-03-30T00:00:00\",\"2021-03-31T00:00:00\",\"2021-04-01T00:00:00\",\"2021-04-05T00:00:00\",\"2021-04-06T00:00:00\",\"2021-04-07T00:00:00\",\"2021-04-08T00:00:00\",\"2021-04-09T00:00:00\",\"2021-04-12T00:00:00\",\"2021-04-13T00:00:00\",\"2021-04-14T00:00:00\",\"2021-04-15T00:00:00\",\"2021-04-16T00:00:00\",\"2021-04-19T00:00:00\",\"2021-04-20T00:00:00\",\"2021-04-21T00:00:00\",\"2021-04-22T00:00:00\",\"2021-04-23T00:00:00\",\"2021-04-26T00:00:00\",\"2021-04-27T00:00:00\",\"2021-04-28T00:00:00\",\"2021-04-29T00:00:00\",\"2021-04-30T00:00:00\",\"2021-05-03T00:00:00\",\"2021-05-04T00:00:00\",\"2021-05-05T00:00:00\",\"2021-05-06T00:00:00\",\"2021-05-07T00:00:00\",\"2021-05-10T00:00:00\",\"2021-05-11T00:00:00\",\"2021-05-12T00:00:00\",\"2021-05-13T00:00:00\",\"2021-05-14T00:00:00\",\"2021-05-17T00:00:00\",\"2021-05-18T00:00:00\",\"2021-05-19T00:00:00\",\"2021-05-20T00:00:00\",\"2021-05-21T00:00:00\",\"2021-05-24T00:00:00\",\"2021-05-25T00:00:00\",\"2021-05-26T00:00:00\",\"2021-05-27T00:00:00\"],\"y\":[1000000.0,1011029.1220835958,1026106.5767197477,1022811.0523890137,1060281.9875751236,1075632.9349828924,1072953.131556852,1057322.1071411895,988315.9928756636,1003778.8950027291,1006184.9780574692,1028313.7681556307,1022380.7634683335,1022091.2574680707,1015648.0025527214,1024761.1588442267,1030968.1736159851,1005993.4714555998,1016016.4626307904,989092.3198200157,1005976.8485630141,1019593.1038931619,1014071.7882665802,1014838.4259264178,1030919.1191582261,1015414.4746222034,1022735.7458922517,1005278.2672090582,1018392.3239289639,1023190.6938744835,1054280.2482043346,1055876.9033542664,1055864.6558443825,1052951.2814614237,1050430.7206067406,1066729.6470173772,1077226.710390426,1059586.9182282223,1057729.7879182762,1063591.492451159,1049447.7940095877,1060953.000493268,1053785.676475724,1062175.0113158086,1069494.2231296555,1078392.1708516786,1088018.0129506055,1098566.160140709,1103382.3232304207,1117881.7825062303,1112223.0687084498,1128381.069040905,1130537.1727087542,1131450.424722656,1132361.836265227,1125629.101487922,1117419.71167292,1114715.1174573454,1127389.1337120668,1139574.1830862816,1138570.4485554406,1137533.5712560983,1139849.9930688883,1141602.6124493254,1142466.902284761,1145939.515283577,1156437.527386233,1122388.6954065524,1115996.3918329687,1090761.788877423,1111532.7003006325,1092155.9508840693,1093237.4430191503,1108741.8433967202,1107013.4079112068,1107632.9235858931,1100443.234599146,1088462.6606485895,1075771.3055820474,1074129.5820416259,1048342.105282863,1050997.0160748765,1067550.9877410813,1085102.1884974125,1073311.550226502,1086331.5858136301,1084033.4750107974,1084472.2632650547,1107554.3380400054,1093172.2952710136,1114862.027567757,1121424.5235409364,1125248.5085354205,1142538.7955175121,1132857.4384216596,1123047.7083558794,1128298.693398845,1128160.5065122796,1108180.4409003905,1124235.2909586153,1131275.9909801688,1138210.0378903307,1138359.0512499716,1114765.6638556672,1107773.1671294481,1077162.2488571021,1088025.7408229737,1074384.066788529,1092245.4532602816,1111045.3597322367,1135435.709128394,1152708.9446566957,1144463.6037325733,1162582.464719032,1180109.8666821995,1187398.947885893,1174841.131690486,1185497.9417775797,1209314.410152957,1196038.4379331584,1179777.0244407607,1179585.6486052072,1175481.0431633506,1185764.9438307255,1205024.1244188002,1197123.3355110385,1197375.558252329,1185899.4262971466,1199428.0550647536,1202432.4815861084,1202693.7860323372,1208511.6429635752,1198231.689454772,1201815.380492987,1197222.5368133697,1204739.5150717187,1196873.8940987652,1192148.034458216,1213438.628579327,1212075.25858777,1218805.631021428,1210225.2993280934,1204983.1056340127,1203129.9472478267,1208520.411273009,1212155.4731932816,1223711.297349585,1216327.2846132042,1214211.9006004226,1218944.208341263,1201604.7860694933,1207964.6720275197,1223648.6727189627,1234736.0172339287,1244371.2016162078,1236003.6121743398,1243525.6741773009,1246808.4509533986,1238272.2519743037,1236849.313209385,1241695.4325306525,1257118.6217702378,1268756.6606605323,1266581.9298826316,1272189.5985345545,1262432.0981892503,1231162.145066583,1232622.8202433826,1203585.0676416315,1212342.7451155274,1223708.8093706244,1224852.4769107618,1238515.063983928,1238314.5516853796,1245398.7759078203,1249502.870473698,1252687.5764818366,1250190.536698049,1248176.754517211,1248385.6234297664,1256486.599659849,1256120.745691733,1247555.1373762887,1248739.2982296704,1247151.4732906513,1254222.397775504,1232739.384856418,1226140.6319920789,1254383.9806759725,1248401.9188027224,1241583.1805208353,1232237.6779306384,1260722.6824073312,1266275.4942212254,1278259.4753076548,1287898.1510222813,1293195.1104616805,1302044.4843409052,1316216.876867613,1315243.3119313803,1317803.2496994915,1308315.6548133031,1301569.7288483782,1306673.5669405244,1304172.3555758144,1312022.184322094,1322576.7851708927,1339119.3810489962,1341060.5486610315,1332873.7527105308,1328014.364995123,1331800.9930626345,1347495.4193200942,1343960.7799391458,1349598.0268504508,1347215.3148804195,1365119.1811104917,1360462.0293329118,1366555.9033906544,1371252.780103578,1383746.1807048956,1390714.9595547304,1387406.1739125291,1385260.289875552,1393575.4356983448,1380786.8414173364,1394742.5219670942,1384625.8699837613,1388249.6720452737,1387317.5854057684,1404643.7283926038,1389210.4638866994,1407861.390709149,1406982.7181180634,1416200.8120163097,1426309.0616942002,1432906.1346230975,1432521.534203867,1401337.394423967,1373445.2996689517,1391765.7157101182,1407875.4874015239,1404860.1627174688,1389735.2821198483,1378554.7418539783,1389436.1851443273,1388323.8611965089,1393791.397560262,1389256.539337995,1391318.2512726467,1392508.4756360394],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"DDPG\",\"x\":[\"2020-06-01T00:00:00\",\"2020-06-02T00:00:00\",\"2020-06-03T00:00:00\",\"2020-06-04T00:00:00\",\"2020-06-05T00:00:00\",\"2020-06-08T00:00:00\",\"2020-06-09T00:00:00\",\"2020-06-10T00:00:00\",\"2020-06-11T00:00:00\",\"2020-06-12T00:00:00\",\"2020-06-15T00:00:00\",\"2020-06-16T00:00:00\",\"2020-06-17T00:00:00\",\"2020-06-18T00:00:00\",\"2020-06-19T00:00:00\",\"2020-06-22T00:00:00\",\"2020-06-23T00:00:00\",\"2020-06-24T00:00:00\",\"2020-06-25T00:00:00\",\"2020-06-26T00:00:00\",\"2020-06-29T00:00:00\",\"2020-06-30T00:00:00\",\"2020-07-01T00:00:00\",\"2020-07-02T00:00:00\",\"2020-07-06T00:00:00\",\"2020-07-07T00:00:00\",\"2020-07-08T00:00:00\",\"2020-07-09T00:00:00\",\"2020-07-10T00:00:00\",\"2020-07-13T00:00:00\",\"2020-07-14T00:00:00\",\"2020-07-15T00:00:00\",\"2020-07-16T00:00:00\",\"2020-07-17T00:00:00\",\"2020-07-20T00:00:00\",\"2020-07-21T00:00:00\",\"2020-07-22T00:00:00\",\"2020-07-23T00:00:00\",\"2020-07-24T00:00:00\",\"2020-07-27T00:00:00\",\"2020-07-28T00:00:00\",\"2020-07-29T00:00:00\",\"2020-07-30T00:00:00\",\"2020-07-31T00:00:00\",\"2020-08-03T00:00:00\",\"2020-08-04T00:00:00\",\"2020-08-05T00:00:00\",\"2020-08-06T00:00:00\",\"2020-08-07T00:00:00\",\"2020-08-10T00:00:00\",\"2020-08-11T00:00:00\",\"2020-08-12T00:00:00\",\"2020-08-13T00:00:00\",\"2020-08-14T00:00:00\",\"2020-08-17T00:00:00\",\"2020-08-18T00:00:00\",\"2020-08-19T00:00:00\",\"2020-08-20T00:00:00\",\"2020-08-21T00:00:00\",\"2020-08-24T00:00:00\",\"2020-08-25T00:00:00\",\"2020-08-26T00:00:00\",\"2020-08-27T00:00:00\",\"2020-08-28T00:00:00\",\"2020-08-31T00:00:00\",\"2020-09-01T00:00:00\",\"2020-09-02T00:00:00\",\"2020-09-03T00:00:00\",\"2020-09-04T00:00:00\",\"2020-09-08T00:00:00\",\"2020-09-09T00:00:00\",\"2020-09-10T00:00:00\",\"2020-09-11T00:00:00\",\"2020-09-14T00:00:00\",\"2020-09-15T00:00:00\",\"2020-09-16T00:00:00\",\"2020-09-17T00:00:00\",\"2020-09-18T00:00:00\",\"2020-09-21T00:00:00\",\"2020-09-22T00:00:00\",\"2020-09-23T00:00:00\",\"2020-09-24T00:00:00\",\"2020-09-25T00:00:00\",\"2020-09-28T00:00:00\",\"2020-09-29T00:00:00\",\"2020-09-30T00:00:00\",\"2020-10-01T00:00:00\",\"2020-10-02T00:00:00\",\"2020-10-05T00:00:00\",\"2020-10-06T00:00:00\",\"2020-10-07T00:00:00\",\"2020-10-08T00:00:00\",\"2020-10-09T00:00:00\",\"2020-10-12T00:00:00\",\"2020-10-13T00:00:00\",\"2020-10-14T00:00:00\",\"2020-10-15T00:00:00\",\"2020-10-16T00:00:00\",\"2020-10-19T00:00:00\",\"2020-10-20T00:00:00\",\"2020-10-21T00:00:00\",\"2020-10-22T00:00:00\",\"2020-10-23T00:00:00\",\"2020-10-26T00:00:00\",\"2020-10-27T00:00:00\",\"2020-10-28T00:00:00\",\"2020-10-29T00:00:00\",\"2020-10-30T00:00:00\",\"2020-11-02T00:00:00\",\"2020-11-03T00:00:00\",\"2020-11-04T00:00:00\",\"2020-11-05T00:00:00\",\"2020-11-06T00:00:00\",\"2020-11-09T00:00:00\",\"2020-11-10T00:00:00\",\"2020-11-11T00:00:00\",\"2020-11-12T00:00:00\",\"2020-11-13T00:00:00\",\"2020-11-16T00:00:00\",\"2020-11-17T00:00:00\",\"2020-11-18T00:00:00\",\"2020-11-19T00:00:00\",\"2020-11-20T00:00:00\",\"2020-11-23T00:00:00\",\"2020-11-24T00:00:00\",\"2020-11-25T00:00:00\",\"2020-11-27T00:00:00\",\"2020-11-30T00:00:00\",\"2020-12-01T00:00:00\",\"2020-12-02T00:00:00\",\"2020-12-03T00:00:00\",\"2020-12-04T00:00:00\",\"2020-12-07T00:00:00\",\"2020-12-08T00:00:00\",\"2020-12-09T00:00:00\",\"2020-12-10T00:00:00\",\"2020-12-11T00:00:00\",\"2020-12-14T00:00:00\",\"2020-12-15T00:00:00\",\"2020-12-16T00:00:00\",\"2020-12-17T00:00:00\",\"2020-12-18T00:00:00\",\"2020-12-21T00:00:00\",\"2020-12-22T00:00:00\",\"2020-12-23T00:00:00\",\"2020-12-24T00:00:00\",\"2020-12-28T00:00:00\",\"2020-12-29T00:00:00\",\"2020-12-30T00:00:00\",\"2020-12-31T00:00:00\",\"2021-01-04T00:00:00\",\"2021-01-05T00:00:00\",\"2021-01-06T00:00:00\",\"2021-01-07T00:00:00\",\"2021-01-08T00:00:00\",\"2021-01-11T00:00:00\",\"2021-01-12T00:00:00\",\"2021-01-13T00:00:00\",\"2021-01-14T00:00:00\",\"2021-01-15T00:00:00\",\"2021-01-19T00:00:00\",\"2021-01-20T00:00:00\",\"2021-01-21T00:00:00\",\"2021-01-22T00:00:00\",\"2021-01-25T00:00:00\",\"2021-01-26T00:00:00\",\"2021-01-27T00:00:00\",\"2021-01-28T00:00:00\",\"2021-01-29T00:00:00\",\"2021-02-01T00:00:00\",\"2021-02-02T00:00:00\",\"2021-02-03T00:00:00\",\"2021-02-04T00:00:00\",\"2021-02-05T00:00:00\",\"2021-02-08T00:00:00\",\"2021-02-09T00:00:00\",\"2021-02-10T00:00:00\",\"2021-02-11T00:00:00\",\"2021-02-12T00:00:00\",\"2021-02-16T00:00:00\",\"2021-02-17T00:00:00\",\"2021-02-18T00:00:00\",\"2021-02-19T00:00:00\",\"2021-02-22T00:00:00\",\"2021-02-23T00:00:00\",\"2021-02-24T00:00:00\",\"2021-02-25T00:00:00\",\"2021-02-26T00:00:00\",\"2021-03-01T00:00:00\",\"2021-03-02T00:00:00\",\"2021-03-03T00:00:00\",\"2021-03-04T00:00:00\",\"2021-03-05T00:00:00\",\"2021-03-08T00:00:00\",\"2021-03-09T00:00:00\",\"2021-03-10T00:00:00\",\"2021-03-11T00:00:00\",\"2021-03-12T00:00:00\",\"2021-03-15T00:00:00\",\"2021-03-16T00:00:00\",\"2021-03-17T00:00:00\",\"2021-03-18T00:00:00\",\"2021-03-19T00:00:00\",\"2021-03-22T00:00:00\",\"2021-03-23T00:00:00\",\"2021-03-24T00:00:00\",\"2021-03-25T00:00:00\",\"2021-03-26T00:00:00\",\"2021-03-29T00:00:00\",\"2021-03-30T00:00:00\",\"2021-03-31T00:00:00\",\"2021-04-01T00:00:00\",\"2021-04-05T00:00:00\",\"2021-04-06T00:00:00\",\"2021-04-07T00:00:00\",\"2021-04-08T00:00:00\",\"2021-04-09T00:00:00\",\"2021-04-12T00:00:00\",\"2021-04-13T00:00:00\",\"2021-04-14T00:00:00\",\"2021-04-15T00:00:00\",\"2021-04-16T00:00:00\",\"2021-04-19T00:00:00\",\"2021-04-20T00:00:00\",\"2021-04-21T00:00:00\",\"2021-04-22T00:00:00\",\"2021-04-23T00:00:00\",\"2021-04-26T00:00:00\",\"2021-04-27T00:00:00\",\"2021-04-28T00:00:00\",\"2021-04-29T00:00:00\",\"2021-04-30T00:00:00\",\"2021-05-03T00:00:00\",\"2021-05-04T00:00:00\",\"2021-05-05T00:00:00\",\"2021-05-06T00:00:00\",\"2021-05-07T00:00:00\",\"2021-05-10T00:00:00\",\"2021-05-11T00:00:00\",\"2021-05-12T00:00:00\",\"2021-05-13T00:00:00\",\"2021-05-14T00:00:00\",\"2021-05-17T00:00:00\",\"2021-05-18T00:00:00\",\"2021-05-19T00:00:00\",\"2021-05-20T00:00:00\",\"2021-05-21T00:00:00\",\"2021-05-24T00:00:00\",\"2021-05-25T00:00:00\",\"2021-05-26T00:00:00\",\"2021-05-27T00:00:00\"],\"y\":[1000000.0,1005022.819895101,1023924.838709092,1026718.7941491125,1044767.9588739449,1058770.8180038948,1042544.4308665437,1040117.0576180072,974505.1120797981,988554.7026158529,1001435.4797506904,1020465.3605499226,1013409.1658560453,1017514.4277639188,1008274.7021590448,1015640.1769202987,1014863.026833658,989223.5105339236,1002022.8122510687,969505.6567758106,984602.713953098,995502.3698452339,1001549.1729470951,1002488.3664661599,1021865.2692507739,1021486.0607744973,1029226.3333703169,1022178.6205470305,1043653.7558043995,1035017.063160954,1058009.0949110286,1066282.3095386017,1059425.404130614,1058891.634816389,1058806.4928431357,1063339.866502342,1066090.034791016,1056996.5710566414,1056338.9702831744,1060933.9618417535,1055461.0175457036,1060424.1665301025,1049331.7004672778,1045222.3728079497,1048015.1170800014,1054154.9405798104,1077356.5690899258,1085780.466538673,1085041.901329779,1092791.4193496397,1091016.4480868503,1098654.6481392211,1094736.3632883253,1092579.7737001476,1091362.848268779,1095014.6044234168,1088385.6696078565,1088421.5332535063,1088723.5261443208,1105060.0806590412,1107406.2598684893,1161919.6910008013,1180943.6680149406,1189777.4439954786,1178949.1537586425,1204121.8783630708,1221110.8011915262,1196312.55045153,1191714.1884430584,1166179.4289398913,1181053.941121822,1167901.369689825,1172073.822568555,1175296.467006159,1171140.0654650407,1174948.3202125626,1164993.6340409054,1157022.9025221323,1141552.453309209,1150381.5797237754,1117408.8010161037,1130287.4315965257,1138433.222405521,1153014.9125651,1148612.5277869701,1161544.9670675178,1160127.4302942448,1157456.2801520193,1169875.303142522,1158419.5683920279,1178516.7990098568,1189832.0097946352,1203100.438048091,1218062.9600354326,1219941.6573567244,1211079.9117370243,1208693.966375256,1211105.394530234,1198157.491224076,1207941.1514163467,1202088.1643589896,1206715.4128906433,1208030.841367417,1178936.2991731311,1174177.571313734,1131455.5339834064,1139943.9803684915,1136181.822559931,1147699.4672728623,1176811.588004246,1173254.4785885613,1201687.5274012322,1201785.6641813007,1259904.7763525224,1262675.2086917595,1260894.4309118064,1247750.3087070582,1264753.079646946,1283917.3694774872,1284661.4166371627,1280630.7592404974,1290515.8732409582,1277635.041368188,1294112.0283196443,1318545.5193511317,1299028.8468966703,1295138.7879312104,1287423.7467194053,1289396.3853918551,1280295.876256378,1279954.963388071,1302679.137038734,1293971.7769036482,1297413.4925878823,1295487.336609331,1295951.1116791032,1322627.359788399,1307533.4923722201,1323398.704787624,1320913.3999528766,1325801.394672264,1328289.0778352022,1333335.5226845313,1324355.982672986,1332551.2561996852,1334278.6707830657,1346887.9292914562,1337674.125017001,1349094.4599047473,1357008.2388015233,1346806.7120649836,1352196.3646215915,1366532.7752782367,1370534.332203005,1378824.9461981903,1374989.7448381435,1381245.4439105939,1380770.7217750468,1375037.632112959,1355358.7728175458,1352880.2139737587,1360901.8866951743,1355723.3548234748,1361270.5241387326,1350992.2609077292,1351476.1674512946,1317595.0648479168,1339732.4403369308,1319436.6537468275,1330670.9103998297,1367819.3165290726,1367563.385433652,1383153.9406302972,1392622.8090755758,1416937.4910352826,1412811.1226759409,1414907.6545512828,1423382.6849713377,1423789.8376759922,1439854.9849362401,1441447.1631820416,1418873.0881464805,1433557.8202921646,1450252.0667544147,1451451.8298368824,1464881.8698775247,1439527.339383177,1400132.5232126347,1428291.2740519736,1417706.9245467903,1403744.823329346,1391613.7588299194,1413707.69069151,1433200.5298214902,1419379.89005359,1442093.2292630028,1444635.3732641363,1458962.381104576,1461052.7550318737,1453119.2000575468,1460873.8961949477,1445739.6051387114,1443528.4529223372,1448486.535707249,1434157.5746689676,1423137.1101210194,1429833.940960717,1442770.9312079558,1449266.811960066,1452147.018685991,1446233.009754198,1459928.019712017,1467264.4932248013,1472131.193699253,1468254.6626325436,1474619.6130328646,1483289.9599848215,1480542.4633508003,1475971.0732774232,1483451.347382502,1491783.9114928667,1498488.7788503852,1496618.295311754,1477148.8434176566,1490843.0377876977,1480661.9923721955,1492636.2722099263,1492718.2605441501,1494388.9517587724,1497889.4701208347,1502440.5871172408,1495764.2642115608,1495516.1296177106,1487979.097119903,1491670.3000745152,1504331.8760457733,1512623.7130027008,1512005.3334031184,1495970.603062816,1471299.6073628897,1485687.050714141,1498416.9232865872,1491655.202598247,1485706.6235805904,1485563.7093349015,1493418.631607854,1499153.1729489234,1511003.907880435,1510909.0815523982,1516888.693783464,1524121.1355317326],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"PPO\",\"x\":[\"2020-06-01T00:00:00\",\"2020-06-02T00:00:00\",\"2020-06-03T00:00:00\",\"2020-06-04T00:00:00\",\"2020-06-05T00:00:00\",\"2020-06-08T00:00:00\",\"2020-06-09T00:00:00\",\"2020-06-10T00:00:00\",\"2020-06-11T00:00:00\",\"2020-06-12T00:00:00\",\"2020-06-15T00:00:00\",\"2020-06-16T00:00:00\",\"2020-06-17T00:00:00\",\"2020-06-18T00:00:00\",\"2020-06-19T00:00:00\",\"2020-06-22T00:00:00\",\"2020-06-23T00:00:00\",\"2020-06-24T00:00:00\",\"2020-06-25T00:00:00\",\"2020-06-26T00:00:00\",\"2020-06-29T00:00:00\",\"2020-06-30T00:00:00\",\"2020-07-01T00:00:00\",\"2020-07-02T00:00:00\",\"2020-07-06T00:00:00\",\"2020-07-07T00:00:00\",\"2020-07-08T00:00:00\",\"2020-07-09T00:00:00\",\"2020-07-10T00:00:00\",\"2020-07-13T00:00:00\",\"2020-07-14T00:00:00\",\"2020-07-15T00:00:00\",\"2020-07-16T00:00:00\",\"2020-07-17T00:00:00\",\"2020-07-20T00:00:00\",\"2020-07-21T00:00:00\",\"2020-07-22T00:00:00\",\"2020-07-23T00:00:00\",\"2020-07-24T00:00:00\",\"2020-07-27T00:00:00\",\"2020-07-28T00:00:00\",\"2020-07-29T00:00:00\",\"2020-07-30T00:00:00\",\"2020-07-31T00:00:00\",\"2020-08-03T00:00:00\",\"2020-08-04T00:00:00\",\"2020-08-05T00:00:00\",\"2020-08-06T00:00:00\",\"2020-08-07T00:00:00\",\"2020-08-10T00:00:00\",\"2020-08-11T00:00:00\",\"2020-08-12T00:00:00\",\"2020-08-13T00:00:00\",\"2020-08-14T00:00:00\",\"2020-08-17T00:00:00\",\"2020-08-18T00:00:00\",\"2020-08-19T00:00:00\",\"2020-08-20T00:00:00\",\"2020-08-21T00:00:00\",\"2020-08-24T00:00:00\",\"2020-08-25T00:00:00\",\"2020-08-26T00:00:00\",\"2020-08-27T00:00:00\",\"2020-08-28T00:00:00\",\"2020-08-31T00:00:00\",\"2020-09-01T00:00:00\",\"2020-09-02T00:00:00\",\"2020-09-03T00:00:00\",\"2020-09-04T00:00:00\",\"2020-09-08T00:00:00\",\"2020-09-09T00:00:00\",\"2020-09-10T00:00:00\",\"2020-09-11T00:00:00\",\"2020-09-14T00:00:00\",\"2020-09-15T00:00:00\",\"2020-09-16T00:00:00\",\"2020-09-17T00:00:00\",\"2020-09-18T00:00:00\",\"2020-09-21T00:00:00\",\"2020-09-22T00:00:00\",\"2020-09-23T00:00:00\",\"2020-09-24T00:00:00\",\"2020-09-25T00:00:00\",\"2020-09-28T00:00:00\",\"2020-09-29T00:00:00\",\"2020-09-30T00:00:00\",\"2020-10-01T00:00:00\",\"2020-10-02T00:00:00\",\"2020-10-05T00:00:00\",\"2020-10-06T00:00:00\",\"2020-10-07T00:00:00\",\"2020-10-08T00:00:00\",\"2020-10-09T00:00:00\",\"2020-10-12T00:00:00\",\"2020-10-13T00:00:00\",\"2020-10-14T00:00:00\",\"2020-10-15T00:00:00\",\"2020-10-16T00:00:00\",\"2020-10-19T00:00:00\",\"2020-10-20T00:00:00\",\"2020-10-21T00:00:00\",\"2020-10-22T00:00:00\",\"2020-10-23T00:00:00\",\"2020-10-26T00:00:00\",\"2020-10-27T00:00:00\",\"2020-10-28T00:00:00\",\"2020-10-29T00:00:00\",\"2020-10-30T00:00:00\",\"2020-11-02T00:00:00\",\"2020-11-03T00:00:00\",\"2020-11-04T00:00:00\",\"2020-11-05T00:00:00\",\"2020-11-06T00:00:00\",\"2020-11-09T00:00:00\",\"2020-11-10T00:00:00\",\"2020-11-11T00:00:00\",\"2020-11-12T00:00:00\",\"2020-11-13T00:00:00\",\"2020-11-16T00:00:00\",\"2020-11-17T00:00:00\",\"2020-11-18T00:00:00\",\"2020-11-19T00:00:00\",\"2020-11-20T00:00:00\",\"2020-11-23T00:00:00\",\"2020-11-24T00:00:00\",\"2020-11-25T00:00:00\",\"2020-11-27T00:00:00\",\"2020-11-30T00:00:00\",\"2020-12-01T00:00:00\",\"2020-12-02T00:00:00\",\"2020-12-03T00:00:00\",\"2020-12-04T00:00:00\",\"2020-12-07T00:00:00\",\"2020-12-08T00:00:00\",\"2020-12-09T00:00:00\",\"2020-12-10T00:00:00\",\"2020-12-11T00:00:00\",\"2020-12-14T00:00:00\",\"2020-12-15T00:00:00\",\"2020-12-16T00:00:00\",\"2020-12-17T00:00:00\",\"2020-12-18T00:00:00\",\"2020-12-21T00:00:00\",\"2020-12-22T00:00:00\",\"2020-12-23T00:00:00\",\"2020-12-24T00:00:00\",\"2020-12-28T00:00:00\",\"2020-12-29T00:00:00\",\"2020-12-30T00:00:00\",\"2020-12-31T00:00:00\",\"2021-01-04T00:00:00\",\"2021-01-05T00:00:00\",\"2021-01-06T00:00:00\",\"2021-01-07T00:00:00\",\"2021-01-08T00:00:00\",\"2021-01-11T00:00:00\",\"2021-01-12T00:00:00\",\"2021-01-13T00:00:00\",\"2021-01-14T00:00:00\",\"2021-01-15T00:00:00\",\"2021-01-19T00:00:00\",\"2021-01-20T00:00:00\",\"2021-01-21T00:00:00\",\"2021-01-22T00:00:00\",\"2021-01-25T00:00:00\",\"2021-01-26T00:00:00\",\"2021-01-27T00:00:00\",\"2021-01-28T00:00:00\",\"2021-01-29T00:00:00\",\"2021-02-01T00:00:00\",\"2021-02-02T00:00:00\",\"2021-02-03T00:00:00\",\"2021-02-04T00:00:00\",\"2021-02-05T00:00:00\",\"2021-02-08T00:00:00\",\"2021-02-09T00:00:00\",\"2021-02-10T00:00:00\",\"2021-02-11T00:00:00\",\"2021-02-12T00:00:00\",\"2021-02-16T00:00:00\",\"2021-02-17T00:00:00\",\"2021-02-18T00:00:00\",\"2021-02-19T00:00:00\",\"2021-02-22T00:00:00\",\"2021-02-23T00:00:00\",\"2021-02-24T00:00:00\",\"2021-02-25T00:00:00\",\"2021-02-26T00:00:00\",\"2021-03-01T00:00:00\",\"2021-03-02T00:00:00\",\"2021-03-03T00:00:00\",\"2021-03-04T00:00:00\",\"2021-03-05T00:00:00\",\"2021-03-08T00:00:00\",\"2021-03-09T00:00:00\",\"2021-03-10T00:00:00\",\"2021-03-11T00:00:00\",\"2021-03-12T00:00:00\",\"2021-03-15T00:00:00\",\"2021-03-16T00:00:00\",\"2021-03-17T00:00:00\",\"2021-03-18T00:00:00\",\"2021-03-19T00:00:00\",\"2021-03-22T00:00:00\",\"2021-03-23T00:00:00\",\"2021-03-24T00:00:00\",\"2021-03-25T00:00:00\",\"2021-03-26T00:00:00\",\"2021-03-29T00:00:00\",\"2021-03-30T00:00:00\",\"2021-03-31T00:00:00\",\"2021-04-01T00:00:00\",\"2021-04-05T00:00:00\",\"2021-04-06T00:00:00\",\"2021-04-07T00:00:00\",\"2021-04-08T00:00:00\",\"2021-04-09T00:00:00\",\"2021-04-12T00:00:00\",\"2021-04-13T00:00:00\",\"2021-04-14T00:00:00\",\"2021-04-15T00:00:00\",\"2021-04-16T00:00:00\",\"2021-04-19T00:00:00\",\"2021-04-20T00:00:00\",\"2021-04-21T00:00:00\",\"2021-04-22T00:00:00\",\"2021-04-23T00:00:00\",\"2021-04-26T00:00:00\",\"2021-04-27T00:00:00\",\"2021-04-28T00:00:00\",\"2021-04-29T00:00:00\",\"2021-04-30T00:00:00\",\"2021-05-03T00:00:00\",\"2021-05-04T00:00:00\",\"2021-05-05T00:00:00\",\"2021-05-06T00:00:00\",\"2021-05-07T00:00:00\",\"2021-05-10T00:00:00\",\"2021-05-11T00:00:00\",\"2021-05-12T00:00:00\",\"2021-05-13T00:00:00\",\"2021-05-14T00:00:00\",\"2021-05-17T00:00:00\",\"2021-05-18T00:00:00\",\"2021-05-19T00:00:00\",\"2021-05-20T00:00:00\",\"2021-05-21T00:00:00\",\"2021-05-24T00:00:00\",\"2021-05-25T00:00:00\",\"2021-05-26T00:00:00\",\"2021-05-27T00:00:00\"],\"y\":[1000000.0,1005019.5582687756,1018927.2672974941,1018058.0734726646,1040226.814820614,1059446.5978203497,1034853.6996465483,1020128.6418803994,948151.837793204,961721.1873659464,971074.3801862659,983003.8589149059,979484.3653289923,983104.3965218994,980073.6654238367,976143.8416705152,976796.1166233675,950336.5907319087,961219.249880362,936857.0572784882,954837.0659701794,966328.096092741,965955.1920094246,972824.6866452062,990228.2506056142,984645.5705661295,996620.6172079282,985575.7132232463,994319.1862384621,981320.6565423891,993406.2467068905,997665.9138320592,995608.9789687321,998922.4328104658,998582.7604754498,996504.6311396754,1004566.2673355886,1000167.9496508699,998420.982975214,995625.2737312596,997718.5979621202,1003700.9836629685,1002476.8631250027,1007330.9404672042,1022688.9188903938,1027538.4206211375,1045145.7581656408,1053741.8723534625,1053652.2598119627,1063096.3531651727,1060508.1399061473,1067897.2904906864,1060590.8810949903,1061743.9551356505,1057817.7810726082,1060249.433967602,1054684.0581468155,1059314.536024336,1057455.553864633,1070347.6241879317,1073953.2096211563,1104132.0013834352,1112072.9899149567,1119150.8431453647,1106601.1319016058,1105777.4921655455,1126785.6793939953,1108472.6702778838,1108258.7427540785,1098687.599627068,1106492.0561137467,1094074.3951491697,1102749.8473557034,1106937.0440315318,1105457.4679804698,1110768.3220948852,1112457.7914649253,1106676.3461338694,1093375.2560839045,1104526.2336430263,1075560.084459394,1082069.9729936267,1094669.4388776745,1106593.344997409,1101907.0614138863,1114611.0813216,1118630.6833384694,1107616.032497831,1121032.8856875515,1112932.4869974505,1133809.4269195776,1141833.467023347,1155557.9651677932,1165502.1885311021,1163375.5819888525,1153591.2705743967,1149461.2795409802,1149903.150661071,1131874.2569883433,1139057.9220485236,1140705.182233288,1140304.4791565312,1146019.4277385033,1120103.499172263,1124996.2596129125,1081796.6974267042,1083415.1659705613,1083805.8528926608,1102198.4564080215,1125243.2809906553,1146799.406935111,1175756.0287784052,1175647.4765012371,1201995.2110928746,1221880.0155428036,1214991.5980894845,1200171.3565711319,1223847.9028201094,1244472.504174503,1221242.904844712,1205832.5074120997,1204755.5281129123,1199844.5973956715,1229229.2391947804,1264474.2479963095,1254180.1830638319,1249313.1954420055,1241374.9096975808,1249705.1452145318,1267752.334521883,1273543.651694313,1286755.6625661622,1277072.6832424477,1279982.637254107,1274492.354998749,1266521.1009292484,1294949.9683058492,1283083.8437093971,1298085.3790600167,1301828.0851847588,1301095.9385543028,1302208.6922361162,1307251.4134332424,1297402.9971498714,1308940.255395644,1313862.2533658931,1327865.6697270854,1324679.891981183,1329766.23041649,1341353.0033701097,1330266.2816105997,1336778.219379794,1362428.7576662223,1382172.9012587026,1382242.479942704,1382260.4033780599,1381143.2135067557,1380410.6837567897,1378201.5850091712,1366645.1200065324,1365306.2067998876,1366626.8011146376,1367428.7532009964,1336996.603726833,1344372.7083976592,1360340.0866556717,1342524.1812076778,1359455.9122179898,1338339.677688864,1346417.8605101416,1355511.7008236852,1362563.112348022,1376006.057753225,1381516.0948060525,1388905.3463297398,1384853.6034237887,1393170.507526197,1387273.4046509804,1387881.427327006,1382263.2847208986,1385717.5564182596,1388359.8991218407,1391621.9972825954,1404404.1588338453,1406482.2903191997,1421819.4419457784,1402292.118026593,1378427.4781160424,1393589.8077280158,1385896.584839298,1386011.3635773635,1369811.6385783514,1398178.8476037541,1426556.867111619,1409396.5119219597,1425989.3293267838,1426012.8388264745,1439228.0818854321,1452169.986792394,1446915.9833364459,1447536.3189506412,1438540.01471935,1430729.7973554772,1438872.3801376356,1431415.1275673031,1425476.0765570493,1437634.4853156232,1453219.0422326413,1459854.4080231711,1455707.5610595548,1460712.7230062922,1469337.961853927,1492784.8883566314,1485562.6792016663,1484441.8415943377,1480975.270441456,1475116.880233635,1477608.723973083,1465765.1722306707,1469757.5435456715,1465068.3894579427,1468643.9561976797,1474205.735774765,1472256.467231627,1484498.3511258855,1469182.0810948333,1475992.9621624334,1470622.8223981955,1469316.0996283367,1463097.9690834624,1477920.3817024492,1471108.7127598338,1491038.2124159702,1487808.637905937,1486787.3256142822,1498321.648446224,1502540.7287047743,1509638.9489269848,1484665.2538050546,1465752.8976111729,1482403.683716894,1493547.81592368,1493437.5654524046,1478723.0101490498,1476830.6804085034,1490697.8030553337,1492817.5397676262,1503333.5952967296,1503173.5843886621,1491469.649834788,1494359.002181903],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"DJIA\",\"x\":[\"2020-06-01T00:00:00\",\"2020-06-02T00:00:00\",\"2020-06-03T00:00:00\",\"2020-06-04T00:00:00\",\"2020-06-05T00:00:00\",\"2020-06-08T00:00:00\",\"2020-06-09T00:00:00\",\"2020-06-10T00:00:00\",\"2020-06-11T00:00:00\",\"2020-06-12T00:00:00\",\"2020-06-15T00:00:00\",\"2020-06-16T00:00:00\",\"2020-06-17T00:00:00\",\"2020-06-18T00:00:00\",\"2020-06-19T00:00:00\",\"2020-06-22T00:00:00\",\"2020-06-23T00:00:00\",\"2020-06-24T00:00:00\",\"2020-06-25T00:00:00\",\"2020-06-26T00:00:00\",\"2020-06-29T00:00:00\",\"2020-06-30T00:00:00\",\"2020-07-01T00:00:00\",\"2020-07-02T00:00:00\",\"2020-07-06T00:00:00\",\"2020-07-07T00:00:00\",\"2020-07-08T00:00:00\",\"2020-07-09T00:00:00\",\"2020-07-10T00:00:00\",\"2020-07-13T00:00:00\",\"2020-07-14T00:00:00\",\"2020-07-15T00:00:00\",\"2020-07-16T00:00:00\",\"2020-07-17T00:00:00\",\"2020-07-20T00:00:00\",\"2020-07-21T00:00:00\",\"2020-07-22T00:00:00\",\"2020-07-23T00:00:00\",\"2020-07-24T00:00:00\",\"2020-07-27T00:00:00\",\"2020-07-28T00:00:00\",\"2020-07-29T00:00:00\",\"2020-07-30T00:00:00\",\"2020-07-31T00:00:00\",\"2020-08-03T00:00:00\",\"2020-08-04T00:00:00\",\"2020-08-05T00:00:00\",\"2020-08-06T00:00:00\",\"2020-08-07T00:00:00\",\"2020-08-10T00:00:00\",\"2020-08-11T00:00:00\",\"2020-08-12T00:00:00\",\"2020-08-13T00:00:00\",\"2020-08-14T00:00:00\",\"2020-08-17T00:00:00\",\"2020-08-18T00:00:00\",\"2020-08-19T00:00:00\",\"2020-08-20T00:00:00\",\"2020-08-21T00:00:00\",\"2020-08-24T00:00:00\",\"2020-08-25T00:00:00\",\"2020-08-26T00:00:00\",\"2020-08-27T00:00:00\",\"2020-08-28T00:00:00\",\"2020-08-31T00:00:00\",\"2020-09-01T00:00:00\",\"2020-09-02T00:00:00\",\"2020-09-03T00:00:00\",\"2020-09-04T00:00:00\",\"2020-09-08T00:00:00\",\"2020-09-09T00:00:00\",\"2020-09-10T00:00:00\",\"2020-09-11T00:00:00\",\"2020-09-14T00:00:00\",\"2020-09-15T00:00:00\",\"2020-09-16T00:00:00\",\"2020-09-17T00:00:00\",\"2020-09-18T00:00:00\",\"2020-09-21T00:00:00\",\"2020-09-22T00:00:00\",\"2020-09-23T00:00:00\",\"2020-09-24T00:00:00\",\"2020-09-25T00:00:00\",\"2020-09-28T00:00:00\",\"2020-09-29T00:00:00\",\"2020-09-30T00:00:00\",\"2020-10-01T00:00:00\",\"2020-10-02T00:00:00\",\"2020-10-05T00:00:00\",\"2020-10-06T00:00:00\",\"2020-10-07T00:00:00\",\"2020-10-08T00:00:00\",\"2020-10-09T00:00:00\",\"2020-10-12T00:00:00\",\"2020-10-13T00:00:00\",\"2020-10-14T00:00:00\",\"2020-10-15T00:00:00\",\"2020-10-16T00:00:00\",\"2020-10-19T00:00:00\",\"2020-10-20T00:00:00\",\"2020-10-21T00:00:00\",\"2020-10-22T00:00:00\",\"2020-10-23T00:00:00\",\"2020-10-26T00:00:00\",\"2020-10-27T00:00:00\",\"2020-10-28T00:00:00\",\"2020-10-29T00:00:00\",\"2020-10-30T00:00:00\",\"2020-11-02T00:00:00\",\"2020-11-03T00:00:00\",\"2020-11-04T00:00:00\",\"2020-11-05T00:00:00\",\"2020-11-06T00:00:00\",\"2020-11-09T00:00:00\",\"2020-11-10T00:00:00\",\"2020-11-11T00:00:00\",\"2020-11-12T00:00:00\",\"2020-11-13T00:00:00\",\"2020-11-16T00:00:00\",\"2020-11-17T00:00:00\",\"2020-11-18T00:00:00\",\"2020-11-19T00:00:00\",\"2020-11-20T00:00:00\",\"2020-11-23T00:00:00\",\"2020-11-24T00:00:00\",\"2020-11-25T00:00:00\",\"2020-11-27T00:00:00\",\"2020-11-30T00:00:00\",\"2020-12-01T00:00:00\",\"2020-12-02T00:00:00\",\"2020-12-03T00:00:00\",\"2020-12-04T00:00:00\",\"2020-12-07T00:00:00\",\"2020-12-08T00:00:00\",\"2020-12-09T00:00:00\",\"2020-12-10T00:00:00\",\"2020-12-11T00:00:00\",\"2020-12-14T00:00:00\",\"2020-12-15T00:00:00\",\"2020-12-16T00:00:00\",\"2020-12-17T00:00:00\",\"2020-12-18T00:00:00\",\"2020-12-21T00:00:00\",\"2020-12-22T00:00:00\",\"2020-12-23T00:00:00\",\"2020-12-24T00:00:00\",\"2020-12-28T00:00:00\",\"2020-12-29T00:00:00\",\"2020-12-30T00:00:00\",\"2020-12-31T00:00:00\",\"2021-01-04T00:00:00\",\"2021-01-05T00:00:00\",\"2021-01-06T00:00:00\",\"2021-01-07T00:00:00\",\"2021-01-08T00:00:00\",\"2021-01-11T00:00:00\",\"2021-01-12T00:00:00\",\"2021-01-13T00:00:00\",\"2021-01-14T00:00:00\",\"2021-01-15T00:00:00\",\"2021-01-19T00:00:00\",\"2021-01-20T00:00:00\",\"2021-01-21T00:00:00\",\"2021-01-22T00:00:00\",\"2021-01-25T00:00:00\",\"2021-01-26T00:00:00\",\"2021-01-27T00:00:00\",\"2021-01-28T00:00:00\",\"2021-01-29T00:00:00\",\"2021-02-01T00:00:00\",\"2021-02-02T00:00:00\",\"2021-02-03T00:00:00\",\"2021-02-04T00:00:00\",\"2021-02-05T00:00:00\",\"2021-02-08T00:00:00\",\"2021-02-09T00:00:00\",\"2021-02-10T00:00:00\",\"2021-02-11T00:00:00\",\"2021-02-12T00:00:00\",\"2021-02-16T00:00:00\",\"2021-02-17T00:00:00\",\"2021-02-18T00:00:00\",\"2021-02-19T00:00:00\",\"2021-02-22T00:00:00\",\"2021-02-23T00:00:00\",\"2021-02-24T00:00:00\",\"2021-02-25T00:00:00\",\"2021-02-26T00:00:00\",\"2021-03-01T00:00:00\",\"2021-03-02T00:00:00\",\"2021-03-03T00:00:00\",\"2021-03-04T00:00:00\",\"2021-03-05T00:00:00\",\"2021-03-08T00:00:00\",\"2021-03-09T00:00:00\",\"2021-03-10T00:00:00\",\"2021-03-11T00:00:00\",\"2021-03-12T00:00:00\",\"2021-03-15T00:00:00\",\"2021-03-16T00:00:00\",\"2021-03-17T00:00:00\",\"2021-03-18T00:00:00\",\"2021-03-19T00:00:00\",\"2021-03-22T00:00:00\",\"2021-03-23T00:00:00\",\"2021-03-24T00:00:00\",\"2021-03-25T00:00:00\",\"2021-03-26T00:00:00\",\"2021-03-29T00:00:00\",\"2021-03-30T00:00:00\",\"2021-03-31T00:00:00\",\"2021-04-01T00:00:00\",\"2021-04-05T00:00:00\",\"2021-04-06T00:00:00\",\"2021-04-07T00:00:00\",\"2021-04-08T00:00:00\",\"2021-04-09T00:00:00\",\"2021-04-12T00:00:00\",\"2021-04-13T00:00:00\",\"2021-04-14T00:00:00\",\"2021-04-15T00:00:00\",\"2021-04-16T00:00:00\",\"2021-04-19T00:00:00\",\"2021-04-20T00:00:00\",\"2021-04-21T00:00:00\",\"2021-04-22T00:00:00\",\"2021-04-23T00:00:00\",\"2021-04-26T00:00:00\",\"2021-04-27T00:00:00\",\"2021-04-28T00:00:00\",\"2021-04-29T00:00:00\",\"2021-04-30T00:00:00\",\"2021-05-03T00:00:00\",\"2021-05-04T00:00:00\",\"2021-05-05T00:00:00\",\"2021-05-06T00:00:00\",\"2021-05-07T00:00:00\",\"2021-05-10T00:00:00\",\"2021-05-11T00:00:00\",\"2021-05-12T00:00:00\",\"2021-05-13T00:00:00\",\"2021-05-14T00:00:00\",\"2021-05-17T00:00:00\",\"2021-05-18T00:00:00\",\"2021-05-19T00:00:00\",\"2021-05-20T00:00:00\",\"2021-05-21T00:00:00\",\"2021-05-24T00:00:00\",\"2021-05-25T00:00:00\",\"2021-05-26T00:00:00\",\"2021-05-27T00:00:00\"],\"y\":[1000000.0,1010505.6193989057,1031201.9817207574,1031670.2713519142,1064218.2407551515,1082332.4166367021,1070550.7309933673,1059468.8730764894,986384.7166456721,1005123.4320385853,1011310.712623656,1031990.5912731602,1025302.8203946723,1023751.8984973786,1015561.9667244484,1021587.4773157829,1026735.2131875507,998858.4865228724,1010621.3884465554,981963.949058552,1004741.1641766097,1013262.456097847,1010204.1598655544,1013830.7977867412,1031874.7455572668,1016296.7551699311,1023248.6481471967,1009070.4665492618,1023563.5246231563,1023975.6931000878,1045831.9692775011,1054762.6696189048,1049448.1036493313,1046984.4463134455,1047334.5901814041,1053596.8523085953,1060091.0358723039,1046214.31380772,1039052.8098527887,1043562.2825976114,1035495.9400331661,1041788.0261070696,1032919.733715856,1037421.0029586268,1046688.123552407,1053128.5626774384,1067772.2738497646,1075052.3835773547,1076877.7011180522,1090929.073441276,1086825.8657186374,1098206.8064533186,1095061.7984376538,1096408.1694613511,1093028.0199429428,1090404.2793146772,1087060.2405389464,1088899.2816952262,1096381.1055714039,1111224.307513257,1108868.2157229693,1112145.169785658,1118439.5559068657,1124783.0097038988,1115997.2123426665,1124460.7730765657,1142315.1202809731,1110606.8214802945,1104348.9294429815,1079523.8288734131,1096779.1670915359,1080846.279405146,1085990.9485471747,1098854.1164329941,1098943.204931914,1100387.0212930704,1095268.2660173369,1085668.25191038,1065659.6037325158,1071174.0438128335,1050563.7032601626,1052617.0321569603,1066690.4849343058,1082788.5926853886,1077630.583268995,1090546.728911057,1091928.520663241,1086664.9390755796,1104950.6984860313,1090195.8183606635,1111028.0368099564,1115818.9586765827,1122154.2089715637,1131992.0479697858,1125801.3173137587,1119292.5667837893,1118515.3041314208,1122916.1379752369,1106786.9795855458,1111237.187778161,1107391.5086853607,1113391.1054104,1112288.4627327155,1086765.8344839949,1078043.9017695787,1041017.8169331006,1046480.4292808279,1040297.5187856354,1056919.730649126,1078704.9353648364,1093135.968829758,1114432.1068203293,1111810.7429076117,1144571.0833452798,1154892.9289645713,1153978.736829353,1141517.080534622,1157204.629841886,1175678.7631265607,1169119.7948971142,1155579.8764261242,1157338.8759362139,1148712.7785261439,1161579.8564923808,1179439.3404691014,1172618.166846964,1174105.8374433892,1163439.3680696692,1170712.3476506157,1173062.4593179123,1176427.7351970861,1186191.8193450836,1180363.7294807022,1184449.763516802,1180325.31869072,1177595.1625405087,1179444.4005731707,1172189.5146976847,1185447.9840468708,1183690.5179016506,1189532.714722832,1184652.7043572855,1186120.7478833806,1178233.0423262364,1182720.5879534248,1185469.9111645054,1193481.7426078387,1190800.6541334526,1193701.1671206697,1201431.0894327385,1186412.8538910274,1192996.1259536564,1210181.6194019716,1218492.9170043257,1220724.1162259895,1217219.4574801747,1219574.7059197843,1219252.0859512337,1216545.4669517698,1209587.2871785392,1214150.9643715003,1224273.0892165345,1223787.4725623522,1216759.8313605315,1215308.1948385404,1214406.8829682262,1189524.894561998,1201308.5735796632,1176941.9491060865,1185942.5708855412,1204610.6748262122,1206028.50065283,1219071.0722283854,1222697.403476598,1232021.0285658208,1231631.2472159844,1234063.8539132623,1233785.0881799804,1234872.4738772127,1237398.462495045,1240941.9153720592,1236243.9920847702,1236282.4795429956,1237356.831638837,1237971.5576150345,1254635.3236664897,1232658.9083515482,1214223.569198073,1237899.3361296796,1232247.123215834,1227480.5051823896,1213900.5658883047,1236360.221141881,1248377.431629177,1249566.862758477,1267791.7475836081,1275193.9131548132,1286697.3697425704,1293559.7908796985,1288554.4279360673,1295990.0208614282,1289981.3772836588,1280782.951436034,1284835.098108517,1272742.906079101,1272621.6169179205,1280449.6745816402,1298247.4406223616,1302113.6668044135,1298015.1358446267,1294662.433557383,1301400.8054765656,1316081.0874010306,1312275.2757948383,1312904.2620643226,1315153.861664421,1326813.5681323837,1324646.6168987534,1321972.275229793,1324077.1251862072,1336053.4714997297,1342517.9844532127,1337688.0384506567,1327626.0981767515,1340030.713298336,1327414.0338152947,1336347.8775546812,1333917.3408999774,1334049.2102787578,1327589.9107658311,1337010.1378418345,1329728.188076401,1339085.5471927533,1339862.8098451218,1343682.5750716266,1356172.905289418,1365171.1503533248,1363799.5554775235,1345206.433078973,1318454.7362190743,1335482.7530952883,1349640.9242816756,1347507.860411662,1337021.94475133,1330559.885181638,1337943.9570473828,1342799.3569067733,1350106.1471830932,1346906.1680368555,1347321.8632529872,1352879.8508955997],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"MVO\",\"x\":[\"2020-06-01T00:00:00\",\"2020-06-02T00:00:00\",\"2020-06-03T00:00:00\",\"2020-06-04T00:00:00\",\"2020-06-05T00:00:00\",\"2020-06-08T00:00:00\",\"2020-06-09T00:00:00\",\"2020-06-10T00:00:00\",\"2020-06-11T00:00:00\",\"2020-06-12T00:00:00\",\"2020-06-15T00:00:00\",\"2020-06-16T00:00:00\",\"2020-06-17T00:00:00\",\"2020-06-18T00:00:00\",\"2020-06-19T00:00:00\",\"2020-06-22T00:00:00\",\"2020-06-23T00:00:00\",\"2020-06-24T00:00:00\",\"2020-06-25T00:00:00\",\"2020-06-26T00:00:00\",\"2020-06-29T00:00:00\",\"2020-06-30T00:00:00\",\"2020-07-01T00:00:00\",\"2020-07-02T00:00:00\",\"2020-07-06T00:00:00\",\"2020-07-07T00:00:00\",\"2020-07-08T00:00:00\",\"2020-07-09T00:00:00\",\"2020-07-10T00:00:00\",\"2020-07-13T00:00:00\",\"2020-07-14T00:00:00\",\"2020-07-15T00:00:00\",\"2020-07-16T00:00:00\",\"2020-07-17T00:00:00\",\"2020-07-20T00:00:00\",\"2020-07-21T00:00:00\",\"2020-07-22T00:00:00\",\"2020-07-23T00:00:00\",\"2020-07-24T00:00:00\",\"2020-07-27T00:00:00\",\"2020-07-28T00:00:00\",\"2020-07-29T00:00:00\",\"2020-07-30T00:00:00\",\"2020-07-31T00:00:00\",\"2020-08-03T00:00:00\",\"2020-08-04T00:00:00\",\"2020-08-05T00:00:00\",\"2020-08-06T00:00:00\",\"2020-08-07T00:00:00\",\"2020-08-10T00:00:00\",\"2020-08-11T00:00:00\",\"2020-08-12T00:00:00\",\"2020-08-13T00:00:00\",\"2020-08-14T00:00:00\",\"2020-08-17T00:00:00\",\"2020-08-18T00:00:00\",\"2020-08-19T00:00:00\",\"2020-08-20T00:00:00\",\"2020-08-21T00:00:00\",\"2020-08-24T00:00:00\",\"2020-08-25T00:00:00\",\"2020-08-26T00:00:00\",\"2020-08-27T00:00:00\",\"2020-08-28T00:00:00\",\"2020-08-31T00:00:00\",\"2020-09-01T00:00:00\",\"2020-09-02T00:00:00\",\"2020-09-03T00:00:00\",\"2020-09-04T00:00:00\",\"2020-09-08T00:00:00\",\"2020-09-09T00:00:00\",\"2020-09-10T00:00:00\",\"2020-09-11T00:00:00\",\"2020-09-14T00:00:00\",\"2020-09-15T00:00:00\",\"2020-09-16T00:00:00\",\"2020-09-17T00:00:00\",\"2020-09-18T00:00:00\",\"2020-09-21T00:00:00\",\"2020-09-22T00:00:00\",\"2020-09-23T00:00:00\",\"2020-09-24T00:00:00\",\"2020-09-25T00:00:00\",\"2020-09-28T00:00:00\",\"2020-09-29T00:00:00\",\"2020-09-30T00:00:00\",\"2020-10-01T00:00:00\",\"2020-10-02T00:00:00\",\"2020-10-05T00:00:00\",\"2020-10-06T00:00:00\",\"2020-10-07T00:00:00\",\"2020-10-08T00:00:00\",\"2020-10-09T00:00:00\",\"2020-10-12T00:00:00\",\"2020-10-13T00:00:00\",\"2020-10-14T00:00:00\",\"2020-10-15T00:00:00\",\"2020-10-16T00:00:00\",\"2020-10-19T00:00:00\",\"2020-10-20T00:00:00\",\"2020-10-21T00:00:00\",\"2020-10-22T00:00:00\",\"2020-10-23T00:00:00\",\"2020-10-26T00:00:00\",\"2020-10-27T00:00:00\",\"2020-10-28T00:00:00\",\"2020-10-29T00:00:00\",\"2020-10-30T00:00:00\",\"2020-11-02T00:00:00\",\"2020-11-03T00:00:00\",\"2020-11-04T00:00:00\",\"2020-11-05T00:00:00\",\"2020-11-06T00:00:00\",\"2020-11-09T00:00:00\",\"2020-11-10T00:00:00\",\"2020-11-11T00:00:00\",\"2020-11-12T00:00:00\",\"2020-11-13T00:00:00\",\"2020-11-16T00:00:00\",\"2020-11-17T00:00:00\",\"2020-11-18T00:00:00\",\"2020-11-19T00:00:00\",\"2020-11-20T00:00:00\",\"2020-11-23T00:00:00\",\"2020-11-24T00:00:00\",\"2020-11-25T00:00:00\",\"2020-11-27T00:00:00\",\"2020-11-30T00:00:00\",\"2020-12-01T00:00:00\",\"2020-12-02T00:00:00\",\"2020-12-03T00:00:00\",\"2020-12-04T00:00:00\",\"2020-12-07T00:00:00\",\"2020-12-08T00:00:00\",\"2020-12-09T00:00:00\",\"2020-12-10T00:00:00\",\"2020-12-11T00:00:00\",\"2020-12-14T00:00:00\",\"2020-12-15T00:00:00\",\"2020-12-16T00:00:00\",\"2020-12-17T00:00:00\",\"2020-12-18T00:00:00\",\"2020-12-21T00:00:00\",\"2020-12-22T00:00:00\",\"2020-12-23T00:00:00\",\"2020-12-24T00:00:00\",\"2020-12-28T00:00:00\",\"2020-12-29T00:00:00\",\"2020-12-30T00:00:00\",\"2020-12-31T00:00:00\",\"2021-01-04T00:00:00\",\"2021-01-05T00:00:00\",\"2021-01-06T00:00:00\",\"2021-01-07T00:00:00\",\"2021-01-08T00:00:00\",\"2021-01-11T00:00:00\",\"2021-01-12T00:00:00\",\"2021-01-13T00:00:00\",\"2021-01-14T00:00:00\",\"2021-01-15T00:00:00\",\"2021-01-19T00:00:00\",\"2021-01-20T00:00:00\",\"2021-01-21T00:00:00\",\"2021-01-22T00:00:00\",\"2021-01-25T00:00:00\",\"2021-01-26T00:00:00\",\"2021-01-27T00:00:00\",\"2021-01-28T00:00:00\",\"2021-01-29T00:00:00\",\"2021-02-01T00:00:00\",\"2021-02-02T00:00:00\",\"2021-02-03T00:00:00\",\"2021-02-04T00:00:00\",\"2021-02-05T00:00:00\",\"2021-02-08T00:00:00\",\"2021-02-09T00:00:00\",\"2021-02-10T00:00:00\",\"2021-02-11T00:00:00\",\"2021-02-12T00:00:00\",\"2021-02-16T00:00:00\",\"2021-02-17T00:00:00\",\"2021-02-18T00:00:00\",\"2021-02-19T00:00:00\",\"2021-02-22T00:00:00\",\"2021-02-23T00:00:00\",\"2021-02-24T00:00:00\",\"2021-02-25T00:00:00\",\"2021-02-26T00:00:00\",\"2021-03-01T00:00:00\",\"2021-03-02T00:00:00\",\"2021-03-03T00:00:00\",\"2021-03-04T00:00:00\",\"2021-03-05T00:00:00\",\"2021-03-08T00:00:00\",\"2021-03-09T00:00:00\",\"2021-03-10T00:00:00\",\"2021-03-11T00:00:00\",\"2021-03-12T00:00:00\",\"2021-03-15T00:00:00\",\"2021-03-16T00:00:00\",\"2021-03-17T00:00:00\",\"2021-03-18T00:00:00\",\"2021-03-19T00:00:00\",\"2021-03-22T00:00:00\",\"2021-03-23T00:00:00\",\"2021-03-24T00:00:00\",\"2021-03-25T00:00:00\",\"2021-03-26T00:00:00\",\"2021-03-29T00:00:00\",\"2021-03-30T00:00:00\",\"2021-03-31T00:00:00\",\"2021-04-01T00:00:00\",\"2021-04-05T00:00:00\",\"2021-04-06T00:00:00\",\"2021-04-07T00:00:00\",\"2021-04-08T00:00:00\",\"2021-04-09T00:00:00\",\"2021-04-12T00:00:00\",\"2021-04-13T00:00:00\",\"2021-04-14T00:00:00\",\"2021-04-15T00:00:00\",\"2021-04-16T00:00:00\",\"2021-04-19T00:00:00\",\"2021-04-20T00:00:00\",\"2021-04-21T00:00:00\",\"2021-04-22T00:00:00\",\"2021-04-23T00:00:00\",\"2021-04-26T00:00:00\",\"2021-04-27T00:00:00\",\"2021-04-28T00:00:00\",\"2021-04-29T00:00:00\",\"2021-04-30T00:00:00\",\"2021-05-03T00:00:00\",\"2021-05-04T00:00:00\",\"2021-05-05T00:00:00\",\"2021-05-06T00:00:00\",\"2021-05-07T00:00:00\",\"2021-05-10T00:00:00\",\"2021-05-11T00:00:00\",\"2021-05-12T00:00:00\",\"2021-05-13T00:00:00\",\"2021-05-14T00:00:00\",\"2021-05-17T00:00:00\",\"2021-05-18T00:00:00\",\"2021-05-19T00:00:00\",\"2021-05-20T00:00:00\",\"2021-05-21T00:00:00\",\"2021-05-24T00:00:00\",\"2021-05-25T00:00:00\",\"2021-05-26T00:00:00\",\"2021-05-27T00:00:00\"],\"y\":[1072701.0712066698,1083866.5622856668,1084865.360338724,1068940.773485876,1103846.0234830831,1105541.9716925947,1107675.0003335744,1108294.224595525,1040800.9556542863,1053371.2721200213,1053974.3884250778,1076697.9377139492,1078413.5371764551,1076660.209061497,1070704.067422743,1083942.3803596906,1097949.2650179418,1070266.3909575213,1082497.5971125914,1055641.7639537395,1071869.1186061199,1086950.0317101807,1088322.4343600338,1092973.616175279,1106456.43087083,1090618.4783577258,1099710.1416350147,1087269.4430743582,1090627.2731585428,1089604.6351149173,1117627.7869277678,1120229.5169794308,1115364.694795876,1119847.724294452,1127307.5743840956,1125651.4959489796,1135670.6360312835,1120035.6585961469,1115045.947479378,1122156.252053346,1118097.0883785163,1129277.927402831,1123229.6895717687,1126817.7967413245,1135143.9649545855,1141054.7452394639,1155261.521469725,1169430.0115017726,1166333.8072828702,1174022.8464005915,1167158.2577557047,1189092.0176303177,1189446.4531131077,1188526.8273008529,1199468.9830020925,1192924.5405334826,1192404.0065028754,1197860.4767192323,1209173.0120195588,1214807.250637304,1219704.8174369305,1230490.3268036665,1229893.3195448655,1238177.117728472,1233175.2201205995,1243926.5224066111,1257223.3896812494,1207880.183175874,1189978.1328612843,1163463.9649215145,1192011.3402126988,1169035.2596759032,1168029.887102547,1192295.271588957,1198652.1121332962,1187672.4237003918,1181661.8189291104,1168757.991176763,1152515.0581471622,1158038.1162863895,1130926.9427299588,1132481.367519442,1154785.0193513813,1169633.3188049342,1167002.9887696193,1184831.9079337483,1193730.5119931644,1184848.2705286867,1203484.94266923,1182107.1399959251,1204972.5315429906,1206798.4196013173,1223563.2622486916,1237364.62704327,1235034.2608706397,1218207.195744852,1215694.6863443574,1219912.348899047,1198795.0695326282,1204217.1035042303,1202150.849248827,1198791.3591030778,1204817.396566925,1179199.275191077,1175012.4788816418,1128849.7868744207,1137665.6067093255,1120864.359617786,1137497.4935703182,1163585.0565382126,1218946.8176034407,1236062.6145738857,1229102.4451712915,1235776.0478377622,1245348.436049875,1250736.5871216087,1243251.9134455158,1250079.7073223663,1259888.7406326854,1241820.1959149893,1223831.4606181015,1218787.3902444004,1206446.9413457867,1211909.1794293553,1220480.7313210838,1221867.4194780986,1230006.5402391062,1231807.4478894859,1242255.057847423,1242116.1026728705,1235814.9436786082,1240331.9238547748,1238763.9954056307,1239102.939594979,1230473.9560849676,1223295.6794260363,1217549.8269968429,1219149.4585230977,1235362.7431780174,1237691.1178637089,1251389.314802292,1241369.80427821,1238671.976685483,1235846.0551191433,1235253.6342017138,1247168.535485292,1263597.2751604104,1261808.7360102367,1263468.5204986618,1268713.4856190605,1258043.6046303809,1252951.3837982474,1258010.9125936818,1270978.78166088,1277627.073233868,1268593.2745452293,1263641.381057392,1262668.7692592707,1235260.3402994415,1241768.1562455527,1241832.9023804523,1257033.707441452,1271429.9200046775,1268045.7166139768,1273634.5682713003,1269080.4194277448,1235137.6404641424,1245240.3214351723,1215053.5000589793,1228111.2732132673,1243738.274800078,1242624.7895676668,1258549.0533107505,1252685.8649385779,1251011.0847971227,1250606.7349870512,1255189.3609529277,1260869.4678280093,1256178.9710658174,1243547.4192835104,1248728.837410669,1254132.3505477742,1238100.9749823762,1236080.7719479394,1233722.1994210954,1240464.5809214085,1214266.514529137,1219533.7106889128,1243225.3426511846,1235849.794357138,1223704.4662362111,1208067.1261508097,1233369.3166482754,1243861.4287752532,1260646.1713480772,1265669.2175280731,1281158.5834174727,1285952.6545698803,1292479.1085118887,1302494.1440790554,1294010.7683308949,1295656.4166350353,1281104.3670130204,1289791.2559868814,1291646.1707988724,1293068.2743722359,1298902.0437728118,1323608.9563369781,1326018.8476521706,1316580.8299383637,1319265.6970071185,1329206.9169668537,1350793.5464443609,1342715.3363677375,1345996.1164920602,1354142.894318715,1377841.3498785638,1375466.497382034,1377445.409898091,1375888.2783472333,1404423.6578932754,1411817.450226063,1408477.8672295224,1404272.245209354,1417201.7394277095,1406930.132887064,1421866.7639375348,1414227.009739126,1412641.9162037475,1414401.007657295,1433104.7510735611,1420101.9578899473,1434550.7932234423,1434545.6287865173,1429756.7416618636,1445425.4289404997,1453106.4824888231,1441872.837134637,1418201.7272578934,1381182.9705426767,1404270.8075638192,1413539.4999994184,1405007.2685847878,1398785.8655915954,1393201.3120125197,1401829.2223274726,1402433.3884033747,1408602.8057003075,1412197.930830377,1409402.4919158607,1407938.8906042662],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Cumulative Returns\"},\"xaxis\":{\"title\":{\"text\":\"Date\"}},\"yaxis\":{\"title\":{\"text\":\"Cumulative Return\"}},\"legend\":{\"title\":{\"text\":\"Strategy\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9591aea6-f828-4f6e-8f35-97b63c78531f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##More Analysis using the pyfolio library for all 4 strategies\n",
        "\n"
      ],
      "metadata": {
        "id": "25bqIJ0t3G-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyfolio"
      ],
      "metadata": {
        "id": "I7i9RaaQ0_mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_daily_return_to_pyfolio_ts(df):\n",
        "    strategy_ret = df.copy()\n",
        "    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n",
        "    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n",
        "    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n",
        "    del strategy_ret[\"date\"]\n",
        "    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)"
      ],
      "metadata": {
        "id": "yAI-sjyx3JMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_daily_return_to_pyfolio_ts(df, strategy_name):\n",
        "    strategy_ret = df.copy()\n",
        "    return pd.Series(strategy_ret[strategy_name].values)  # Using the provided strategy_name\n",
        "\n",
        "from pyfolio import timeseries\n",
        "\n",
        "def calculate_performance_stats(df):\n",
        "    strategy_stats = {}\n",
        "    strategy_names = ['daily_return_a2c', 'daily_return_ddpg', 'daily_return_ppo', 'daily_return_DJIA']\n",
        "\n",
        "    for strategy_name in strategy_names:\n",
        "        # Convert daily return to pyfolio time series format\n",
        "        strategy_returns = convert_daily_return_to_pyfolio_ts(df, strategy_name)\n",
        "\n",
        "        # Calculate performance statistics\n",
        "        perf_func = timeseries.perf_stats\n",
        "        perf_stats = perf_func(returns=strategy_returns, factor_returns=strategy_returns, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "\n",
        "        # Store the performance statistics\n",
        "        strategy_stats[strategy_name] = perf_stats\n",
        "\n",
        "    # Create a DataFrame from the performance statistics dictionary\n",
        "    df_performance_stats = pd.DataFrame(strategy_stats)\n",
        "\n",
        "    return df_performance_stats\n",
        "\n",
        "# Call the function with the provided DataFrame\n",
        "df_performance_stats = calculate_performance_stats(final_df)\n"
      ],
      "metadata": {
        "id": "s9jXBbwm3p4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_performance_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "csyrPBmK47Gi",
        "outputId": "fedd1632-ac28-4088-b36c-3e190cae6587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     daily_return_a2c  daily_return_ddpg  daily_return_ppo  \\\n",
              "Annual return                0.394347           0.526682          0.496752   \n",
              "Cumulative returns           0.392508           0.524121          0.494359   \n",
              "Annual volatility            0.180442           0.187850          0.178559   \n",
              "Sharpe ratio                 1.933925           2.347996          2.350071   \n",
              "Calmar ratio                 4.218839           6.201783          4.293047   \n",
              "Stability                    0.937966           0.960497          0.961594   \n",
              "Max drawdown                -0.093473          -0.084924         -0.115711   \n",
              "Omega ratio                  1.390841           1.518774          1.508641   \n",
              "Sortino ratio                2.742065           3.522019          3.361386   \n",
              "Skew                        -0.949529          -0.484632         -1.228960   \n",
              "Kurtosis                     4.399620           4.962146          6.536163   \n",
              "Tail ratio                   0.958818           1.222573          1.228560   \n",
              "Daily value at risk         -0.021349          -0.021917         -0.020831   \n",
              "Alpha                        0.000000           0.000000          0.000000   \n",
              "Beta                         1.000000           1.000000          1.000000   \n",
              "\n",
              "                     daily_return_DJIA  \n",
              "Annual return                 0.354510  \n",
              "Cumulative returns            0.352880  \n",
              "Annual volatility             0.174486  \n",
              "Sharpe ratio                  1.827713  \n",
              "Calmar ratio                  3.822889  \n",
              "Stability                     0.943069  \n",
              "Max drawdown                 -0.092733  \n",
              "Omega ratio                   1.376623  \n",
              "Sortino ratio                 2.542411  \n",
              "Skew                         -1.238262  \n",
              "Kurtosis                      6.454752  \n",
              "Tail ratio                    1.067640  \n",
              "Daily value at risk          -0.020718  \n",
              "Alpha                         0.000000  \n",
              "Beta                          1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecddb769-aab8-4752-b5c5-cae865d1ebec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>daily_return_a2c</th>\n",
              "      <th>daily_return_ddpg</th>\n",
              "      <th>daily_return_ppo</th>\n",
              "      <th>daily_return_DJIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>0.394347</td>\n",
              "      <td>0.526682</td>\n",
              "      <td>0.496752</td>\n",
              "      <td>0.354510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>0.392508</td>\n",
              "      <td>0.524121</td>\n",
              "      <td>0.494359</td>\n",
              "      <td>0.352880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>0.180442</td>\n",
              "      <td>0.187850</td>\n",
              "      <td>0.178559</td>\n",
              "      <td>0.174486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.933925</td>\n",
              "      <td>2.347996</td>\n",
              "      <td>2.350071</td>\n",
              "      <td>1.827713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>4.218839</td>\n",
              "      <td>6.201783</td>\n",
              "      <td>4.293047</td>\n",
              "      <td>3.822889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.937966</td>\n",
              "      <td>0.960497</td>\n",
              "      <td>0.961594</td>\n",
              "      <td>0.943069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-0.093473</td>\n",
              "      <td>-0.084924</td>\n",
              "      <td>-0.115711</td>\n",
              "      <td>-0.092733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.390841</td>\n",
              "      <td>1.518774</td>\n",
              "      <td>1.508641</td>\n",
              "      <td>1.376623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>2.742065</td>\n",
              "      <td>3.522019</td>\n",
              "      <td>3.361386</td>\n",
              "      <td>2.542411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>-0.949529</td>\n",
              "      <td>-0.484632</td>\n",
              "      <td>-1.228960</td>\n",
              "      <td>-1.238262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>4.399620</td>\n",
              "      <td>4.962146</td>\n",
              "      <td>6.536163</td>\n",
              "      <td>6.454752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>0.958818</td>\n",
              "      <td>1.222573</td>\n",
              "      <td>1.228560</td>\n",
              "      <td>1.067640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.021917</td>\n",
              "      <td>-0.020831</td>\n",
              "      <td>-0.020718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alpha</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beta</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecddb769-aab8-4752-b5c5-cae865d1ebec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ecddb769-aab8-4752-b5c5-cae865d1ebec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ecddb769-aab8-4752-b5c5-cae865d1ebec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b11afc36-cfd8-4c44-a112-e066de26203f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b11afc36-cfd8-4c44-a112-e066de26203f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b11afc36-cfd8-4c44-a112-e066de26203f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_15ae8f4c-5395-471d-a645-ae7b8cb103c2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_performance_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_15ae8f4c-5395-471d-a645-ae7b8cb103c2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_performance_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_performance_stats",
              "summary": "{\n  \"name\": \"df_performance_stats\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"daily_return_a2c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5588227462771997,\n        \"min\": -0.9495286816238491,\n        \"max\": 4.399619635103415,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.9495286816238491,\n          0.9588175606591166,\n          0.39434661603512433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_ddpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9668094438234334,\n        \"min\": -0.48463184908108026,\n        \"max\": 6.20178340861303,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.48463184908108026,\n          1.2225726858129886,\n          0.5266822171258871\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_ppo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0037173200323024,\n        \"min\": -1.2289600074193066,\n        \"max\": 6.53616307438784,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -1.2289600074193066,\n          1.2285604550583487,\n          0.4967524709214757\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return_DJIA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8870245405900419,\n        \"min\": -1.238262060147214,\n        \"max\": 6.45475205920437,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -1.238262060147214,\n          1.0676399251699291,\n          0.35450986942953255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPp7inPv5Di_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}